"""
GST íŠ¹í—ˆ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
======================================
ì—‘ì…€ íŒŒì¼ê³¼ PDF íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ SQLite ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python scripts/update_patent_database.py
"""

import pandas as pd
import sqlite3
import json
import os
from pathlib import Path
from datetime import datetime
import PyPDF2
import re
from typing import Dict, List, Optional

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
EXCEL_PATH = BASE_DIR / 'db' / 'GST ì§€ì‹ì¬ì‚°ê¶Œ ê´€ë¦¬í˜„í™©_20250924.xlsx'
PDF_DIR = BASE_DIR / 'db' / 'pdf'
DB_PATH = BASE_DIR / 'db' / 'patents.db'
SCHEMA_PATH = BASE_DIR / 'db' / 'schema.sql'


def create_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° ìŠ¤í‚¤ë§ˆ ì ìš©"""
    print("ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    
    # ê¸°ì¡´ DB ë°±ì—…
    if DB_PATH.exists():
        backup_path = DB_PATH.with_suffix('.db.backup')
        import shutil
        shutil.copy2(DB_PATH, backup_path)
        print(f"âœ… ê¸°ì¡´ DB ë°±ì—…: {backup_path}")
    
    # ìƒˆ DB ìƒì„±
    conn = sqlite3.connect(DB_PATH)
    
    # ìŠ¤í‚¤ë§ˆ ì ìš©
    with open(SCHEMA_PATH, 'r', encoding='utf-8') as f:
        schema_sql = f.read()
    
    conn.executescript(schema_sql)
    conn.commit()
    
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    return conn


def extract_excel_data() -> pd.DataFrame:
    """ì—‘ì…€ íŒŒì¼ì—ì„œ íŠ¹í—ˆ ë°ì´í„° ì¶”ì¶œ"""
    print("\nğŸ“Š ì—‘ì…€ íŒŒì¼ ë¶„ì„ ì¤‘...")
    
    # ì—‘ì…€ íŒŒì¼ ì½ê¸° (Row 3ì´ í—¤ë”)
    df = pd.read_excel(
        EXCEL_PATH,
        sheet_name='GST ì§€ì‹ì¬ì‚°ê¶Œ í˜„í™©_ìµœì‹ ',
        header=3  # 0-based indexì´ë¯€ë¡œ Row 3
    )
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬ (ëª¨ë“  ê³µë°± ì œê±°)
    df.columns = [re.sub(r'\s+', '', str(col)) for col in df.columns]
    
    # NO ì»¬ëŸ¼ì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
    df_clean = df[df['NO'].notna()].copy()
    
    # ë‚ ì§œ í˜•ì‹ í†µì¼
    for date_col in ['ì¶œì›ì¼', 'ë“±ë¡ì¼']:
        if date_col in df_clean.columns:
            df_clean[date_col] = pd.to_datetime(df_clean[date_col], errors='coerce')
            df_clean[date_col] = df_clean[date_col].dt.strftime('%Y-%m-%d')
    
    print(f"âœ… ì—‘ì…€ì—ì„œ {len(df_clean)}ê°œ íŠ¹í—ˆ ë°ì´í„° ì¶”ì¶œ")
    print(f"   ì»¬ëŸ¼: {', '.join(df_clean.columns[:10].tolist())}")
    
    return df_clean


def extract_pdf_metadata(pdf_path: Path) -> Dict:
    """PDF íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PyPDF2.PdfReader(f)
            
            metadata = {
                'page_count': len(pdf.pages),
                'title': pdf.metadata.get('/Title', '') if pdf.metadata else '',
                'author': pdf.metadata.get('/Author', '') if pdf.metadata else '',
                'full_text': '',
            }
            
            # ì²« 3í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (íŠ¹í—ˆë²ˆí˜¸ ì°¾ê¸°ìš©)
            for i in range(min(3, len(pdf.pages))):
                try:
                    text = pdf.pages[i].extract_text()
                    metadata['full_text'] += text + '\n'
                except:
                    pass
            
            return metadata
    except Exception as e:
        print(f"  âš ï¸ PDF ì½ê¸° ì˜¤ë¥˜ ({pdf_path.name}): {e}")
        return {'page_count': 0, 'title': '', 'author': '', 'full_text': ''}


def match_pdf_to_patent(patent_number: str, pdf_files: List[Path]) -> Optional[Path]:
    """íŠ¹í—ˆ ë²ˆí˜¸ì™€ PDF íŒŒì¼ ë§¤ì¹­"""
    if not patent_number or pd.isna(patent_number):
        return None
    
    # íŠ¹í—ˆë²ˆí˜¸ ì •ê·œí™” (í•˜ì´í”ˆ ì œê±°)
    clean_patent_num = str(patent_number).replace('-', '').strip()
    
    # PDF íŒŒì¼ëª…ì—ì„œ ë§¤ì¹­ ì‹œë„
    for pdf_path in pdf_files:
        pdf_name = pdf_path.stem  # í™•ì¥ì ì œì™¸
        
        # íŒŒì¼ëª…ì— íŠ¹í—ˆë²ˆí˜¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if clean_patent_num in pdf_name.replace('-', ''):
            return pdf_path
        
        # PDF ë‚´ìš©ì—ì„œ íŠ¹í—ˆë²ˆí˜¸ ê²€ìƒ‰
        metadata = extract_pdf_metadata(pdf_path)
        if clean_patent_num in metadata['full_text'].replace('-', ''):
            return pdf_path
    
    return None


def normalize_patent_id(row_index: int, patent_number: str) -> str:
    """íŠ¹í—ˆ ID ìƒì„± (ê³ ìœ  ì‹ë³„ì)"""
    if patent_number and not pd.isna(patent_number):
        clean_num = str(patent_number).replace('-', '').strip()
        return f"KR{clean_num}"
    else:
        return f"GST{row_index:04d}"


def categorize_technology(title: str, tech_field: str) -> str:
    """ê¸°ìˆ  ë¶„ì•¼ ìë™ ë¶„ë¥˜"""
    title_lower = str(title).lower() if title else ''
    tech_lower = str(tech_field).lower() if tech_field else ''
    combined = title_lower + ' ' + tech_lower
    
    # ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë§¤ì¹­
    categories = {
        'scrubber': ['ìŠ¤í¬ëŸ¬ë²„', 'scrubber', 'ì •í™”', 'ì²˜ë¦¬ì¥ì¹˜', 'ë°°ê°€ìŠ¤'],
        'chiller': ['ì¹ ëŸ¬', 'chiller', 'ëƒ‰ê°', 'ì˜¨ë„ì œì–´', 'ëƒ‰ë§¤'],
        'plasma': ['í”Œë¼ì¦ˆë§ˆ', 'plasma', 'ë²„ë„ˆ', 'ì—°ì†Œ'],
        'temperature': ['ì˜¨ë„', 'temperature', 'íˆí„°', 'ê°€ì—´'],
        'gas-treatment': ['ê°€ìŠ¤', 'ì§‘ì§„', 'í¡ì°©', 'í•„í„°'],
    }
    
    for category, keywords in categories.items():
        if any(kw in combined for kw in keywords):
            return category
    
    return 'other'


def insert_patent_data(conn: sqlite3.Connection, df: pd.DataFrame, pdf_files: List[Path]):
    """ì—‘ì…€ ë°ì´í„°ì™€ PDFë¥¼ ë§¤ì¹­í•˜ì—¬ DBì— ì‚½ì…"""
    print("\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")
    
    cursor = conn.cursor()
    inserted_count = 0
    pdf_matched_count = 0
    
    for idx, row in df.iterrows():
        try:
            # ê¸°ë³¸ ì •ë³´
            patent_id = normalize_patent_id(idx, row.get('ë“±ë¡ë²ˆí˜¸'))
            patent_number = str(row.get('ë“±ë¡ë²ˆí˜¸', '')).strip() if pd.notna(row.get('ë“±ë¡ë²ˆí˜¸')) else ''
            application_number = str(row.get('ì¶œì›ë²ˆí˜¸', '')).strip() if pd.notna(row.get('ì¶œì›ë²ˆí˜¸')) else ''
            title = str(row.get('ëª…ì¹­', '')).strip() if pd.notna(row.get('ëª…ì¹­')) else ''
            
            # PDF ë§¤ì¹­
            pdf_path = match_pdf_to_patent(patent_number or application_number, pdf_files)
            pdf_metadata = {}
            
            if pdf_path:
                pdf_metadata = extract_pdf_metadata(pdf_path)
                pdf_matched_count += 1
                print(f"  âœ“ PDF ë§¤ì¹­: {patent_number} â†’ {pdf_path.name}")
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            tech_field = str(row.get('ê¸°ìˆ ë¶„ë¥˜', '')).strip() if pd.notna(row.get('ê¸°ìˆ ë¶„ë¥˜')) else ''
            product_group = str(row.get('ì ìš© ì œí’ˆêµ°', '')).strip() if pd.notna(row.get('ì ìš© ì œí’ˆêµ°')) else ''
            category = categorize_technology(title, tech_field)
            
            # íŠ¹í—ˆ ê¸°ë³¸ ì •ë³´ ì‚½ì…
            cursor.execute("""
                INSERT INTO patents (
                    id, patent_number, title, abstract, category, technology_field,
                    registration_date, application_date, status, assignee,
                    priority_score, page_count, source_path, extraction_date,
                    ipc_classification, legal_status, full_text
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                patent_id,
                patent_number,
                title,
                '',  # abstract (PDFì—ì„œ ì¶”ì¶œ ê°€ëŠ¥)
                category,
                tech_field,
                row.get('ë“±ë¡ì¼'),
                row.get('ì¶œì›ì¼'),
                str(row.get('ìƒíƒœ', '')).strip() if pd.notna(row.get('ìƒíƒœ')) else 'unknown',
                'GST (Global Standard Technology)',
                5,  # ê¸°ë³¸ ìš°ì„ ìˆœìœ„
                pdf_metadata.get('page_count', 0),
                pdf_path.name if pdf_path else '',
                datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                '',  # IPC ë¶„ë¥˜
                str(row.get('ì¡´ì†ì—¬ë¶€', '')).strip() if pd.notna(row.get('ì¡´ì†ì—¬ë¶€')) else '',
                pdf_metadata.get('full_text', '')[:5000]  # ì²˜ìŒ 5000ìë§Œ
            ))
            
            # ë°œëª…ì ì •ë³´ ì‚½ì…
            inventor = str(row.get('ê³ ì•ˆì', '')).strip() if pd.notna(row.get('ê³ ì•ˆì')) else ''
            if inventor:
                for name in inventor.split(','):
                    name = name.strip()
                    if name and name not in ['ãˆœê¸€ë¡œë²ŒìŠ¤íƒ ë‹¤ë“œí…Œí¬ë†€ë¡œì§€', 'GST']:
                        cursor.execute(
                            "INSERT INTO patent_inventors (patent_id, name) VALUES (?, ?)",
                            (patent_id, name)
                        )
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì‚½ì… (ì œëª©ì—ì„œ)
            if title:
                keywords = extract_keywords(title)
                for keyword in keywords[:10]:  # ìµœëŒ€ 10ê°œ
                    cursor.execute(
                        "INSERT INTO patent_keywords (patent_id, keyword) VALUES (?, ?)",
                        (patent_id, keyword)
                    )
            
            # FTS5 í…Œì´ë¸”ì— ê²€ìƒ‰ ë°ì´í„° ì‚½ì…
            cursor.execute("""
                INSERT INTO patent_search (patent_id, title, abstract, technology_field, full_text)
                VALUES (?, ?, ?, ?, ?)
            """, (
                patent_id,
                title,
                '',
                tech_field,
                pdf_metadata.get('full_text', '')[:10000]
            ))
            
            inserted_count += 1
            
            if inserted_count % 10 == 0:
                print(f"  ğŸ“ {inserted_count}ê°œ ì²˜ë¦¬ ì™„ë£Œ...")
        
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜ (Row {idx}): {e}")
            continue
    
    conn.commit()
    print(f"\nâœ… ì´ {inserted_count}ê°œ íŠ¹í—ˆ ë°ì´í„° ì‚½ì… ì™„ë£Œ")
    print(f"âœ… PDF ë§¤ì¹­: {pdf_matched_count}ê°œ")


def extract_keywords(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # í•œê¸€ ëª…ì‚¬ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
    words = re.findall(r'[ê°€-í£]{2,}', text)
    
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = {'ì´ë¥¼', 'ìœ„í•œ', 'êµ¬ë¹„í•œ', 'í¬í•¨í•œ', 'ê°–ëŠ”', 'ìˆëŠ”', 'í•˜ëŠ”', 'ë˜ëŠ”', 'ë°', 'ë˜ëŠ”'}
    keywords = [w for w in words if w not in stopwords]
    
    # ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ìˆœ ì •ë ¬
    from collections import Counter
    word_counts = Counter(keywords)
    return [word for word, count in word_counts.most_common(20)]


def generate_statistics(conn: sqlite3.Connection):
    """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ìƒì„±"""
    print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
    
    cursor = conn.cursor()
    
    # ì´ íŠ¹í—ˆ ìˆ˜
    total = cursor.execute("SELECT COUNT(*) FROM patents").fetchone()[0]
    print(f"  â€¢ ì´ íŠ¹í—ˆ ìˆ˜: {total}")
    
    # ì¹´í…Œê³ ë¦¬ë³„
    categories = cursor.execute("""
        SELECT category, COUNT(*) as cnt 
        FROM patents 
        GROUP BY category 
        ORDER BY cnt DESC
    """).fetchall()
    print(f"  â€¢ ì¹´í…Œê³ ë¦¬ë³„:")
    for cat, cnt in categories:
        print(f"    - {cat}: {cnt}ê°œ")
    
    # ìƒíƒœë³„
    statuses = cursor.execute("""
        SELECT status, COUNT(*) as cnt 
        FROM patents 
        GROUP BY status 
        ORDER BY cnt DESC
    """).fetchall()
    print(f"  â€¢ ìƒíƒœë³„:")
    for status, cnt in statuses:
        print(f"    - {status}: {cnt}ê°œ")
    
    # PDF ë§¤ì¹­ ìˆ˜
    pdf_count = cursor.execute("""
        SELECT COUNT(*) FROM patents WHERE source_path != ''
    """).fetchone()[0]
    print(f"  â€¢ PDF ë§¤ì¹­: {pdf_count}ê°œ")


def export_to_json(conn: sqlite3.Connection):
    """JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (ì›¹ ì•±ìš©)"""
    print("\nğŸ“¤ JSON íŒŒì¼ ìƒì„± ì¤‘...")
    
    cursor = conn.cursor()
    
    patents = cursor.execute("""
        SELECT 
            id, patent_number, title, abstract, category, technology_field,
            registration_date, application_date, status, assignee,
            priority_score, page_count, source_path
        FROM patents
        ORDER BY registration_date DESC
    """).fetchall()
    
    patents_data = []
    for patent in patents:
        # ë°œëª…ì ì¡°íšŒ
        inventors = cursor.execute(
            "SELECT name FROM patent_inventors WHERE patent_id = ?",
            (patent[0],)
        ).fetchall()
        
        # í‚¤ì›Œë“œ ì¡°íšŒ
        keywords = cursor.execute(
            "SELECT keyword FROM patent_keywords WHERE patent_id = ?",
            (patent[0],)
        ).fetchall()
        
        patents_data.append({
            'id': patent[0],
            'patent_number': patent[1],
            'title': patent[2],
            'abstract': patent[3],
            'category': patent[4],
            'technology_field': patent[5],
            'registration_date': patent[6],
            'application_date': patent[7],
            'status': patent[8],
            'assignee': patent[9],
            'priority_score': patent[10],
            'page_count': patent[11],
            'source_path': patent[12],
            'inventors': [inv[0] for inv in inventors],
            'technical_keywords': [kw[0] for kw in keywords],
        })
    
    # JSON ì €ì¥
    json_path = BASE_DIR / 'db' / 'patents_data.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(patents_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… JSON íŒŒì¼ ìƒì„±: {json_path}")
    print(f"   {len(patents_data)}ê°œ íŠ¹í—ˆ ë°ì´í„°")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("GST íŠ¹í—ˆ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸")
    print("=" * 60)
    
    # 1. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    conn = create_database()
    
    # 2. ì—‘ì…€ ë°ì´í„° ì¶”ì¶œ
    df = extract_excel_data()
    
    # 3. PDF íŒŒì¼ ëª©ë¡
    pdf_files = list(PDF_DIR.glob('*.pdf'))
    print(f"\nğŸ“ PDF íŒŒì¼: {len(pdf_files)}ê°œ ë°œê²¬")
    
    # 4. ë°ì´í„° ì‚½ì…
    insert_patent_data(conn, df, pdf_files)
    
    # 5. í†µê³„ ìƒì„±
    generate_statistics(conn)
    
    # 6. JSON ë‚´ë³´ë‚´ê¸°
    export_to_json(conn)
    
    # 7. ì •ë¦¬
    conn.close()
    
    print("\n" + "=" * 60)
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    print(f"\në‹¤ìŒ íŒŒì¼ì´ ìƒì„±/ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"  â€¢ {DB_PATH}")
    print(f"  â€¢ {BASE_DIR / 'db' / 'patents_data.json'}")
    print(f"\ní”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ì„ ìœ„í•´ js íŒŒì¼ë“¤ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")


if __name__ == '__main__':
    main()
