# ğŸ”¬ Langchainì„ í™œìš©í•œ íŠ¹í—ˆ ë¶„ì„ ì‹œìŠ¤í…œ ê°œë°œ ê°€ì´ë“œ

> í•œêµ­/ë¯¸êµ­ íŠ¹í—ˆì²­ ë°ì´í„°ì™€ ë²¡í„° ìœ ì‚¬ë„ë¥¼ í™œìš©í•œ AI íŠ¹í—ˆ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš” ë° ì•„í‚¤í…ì²˜](#1-ì‹œìŠ¤í…œ-ê°œìš”-ë°-ì•„í‚¤í…ì²˜)
2. [ê°œë°œ í™˜ê²½ ì„¤ì •](#2-ê°œë°œ-í™˜ê²½-ì„¤ì •)
3. [íŠ¹í—ˆì²­ API ì—°ë™](#3-íŠ¹í—ˆì²­-api-ì—°ë™)
4. [PDF ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ](#4-pdf-ì²˜ë¦¬-ë°-í…ìŠ¤íŠ¸-ì¶”ì¶œ)
5. [í…ìŠ¤íŠ¸ ì„ë² ë”© ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤](#5-í…ìŠ¤íŠ¸-ì„ë² ë”©-ë°-ë²¡í„°-ë°ì´í„°ë² ì´ìŠ¤)
6. [ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ](#6-ìœ ì‚¬ë„-ê²€ìƒ‰-ì‹œìŠ¤í…œ)
7. [ì–¸ì–´ëª¨ë¸ í†µí•©](#7-ì–¸ì–´ëª¨ë¸-í†µí•©)
8. [ì›¹ ì¸í„°í˜ì´ìŠ¤ ì—°ë™](#8-ì›¹-ì¸í„°í˜ì´ìŠ¤-ì—°ë™)
9. [ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ](#9-ì‹¤ì œ-êµ¬í˜„-ì˜ˆì‹œ)
10. [í…ŒìŠ¤íŠ¸ ë° ë°°í¬](#10-í…ŒìŠ¤íŠ¸-ë°-ë°°í¬)

---

## 1. ì‹œìŠ¤í…œ ê°œìš” ë° ì•„í‚¤í…ì²˜

### 1.1 ì‹œìŠ¤í…œ êµ¬ì„±ë„

```mermaid
graph TB
    A[ì›¹ ì¸í„°í˜ì´ìŠ¤] --> B[FastAPI ë°±ì—”ë“œ]
    B --> C[íŠ¹í—ˆì²­ API ì—°ë™]
    B --> D[PDF ì²˜ë¦¬ ëª¨ë“ˆ]
    B --> E[ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤]
    B --> F[ì–¸ì–´ëª¨ë¸ LLM]
    
    C --> G[í•œêµ­ íŠ¹í—ˆì²­ KIPRIS]
    C --> H[USPTO ë¯¸êµ­ íŠ¹í—ˆì²­]
    D --> I[ê¸°ì¡´ íŠ¹í—ˆ PDF]
    E --> J[Chroma/FAISS]
    F --> K[OpenAI/Claude]
```

### 1.2 ì£¼ìš” ê¸°ëŠ¥

1. **íŠ¹í—ˆ ê²€ìƒ‰**: í•œêµ­/ë¯¸êµ­ íŠ¹í—ˆì²­ì—ì„œ ì‹¤ì‹œê°„ ê²€ìƒ‰
2. **PDF ë¶„ì„**: ê¸°ì¡´ ë³´ìœ  íŠ¹í—ˆ PDF ìë™ ì²˜ë¦¬
3. **ìœ ì‚¬ë„ ë¶„ì„**: ë²¡í„° ì„ë² ë”©ì„ í†µí•œ ìœ ì‚¬ íŠ¹í—ˆ ë°œê²¬
4. **ê¸°ìˆ  ë¶„ì„**: LLMì„ í™œìš©í•œ íŠ¹í—ˆ ê¸°ìˆ  ë¶„ì„
5. **ë¹„êµ ë¦¬í¬íŠ¸**: ìë™í™”ëœ íŠ¹í—ˆ ë¹„êµ ë³´ê³ ì„œ ìƒì„±

---

## 2. ê°œë°œ í™˜ê²½ ì„¤ì •

### 2.1 Python í™˜ê²½ êµ¬ì¶•

**Step 1: Python ê°€ìƒí™˜ê²½ ìƒì„±**
```bash
# í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™
cd ~/Development/gst-patent-management

# ë°±ì—”ë“œ í´ë” ìƒì„±
mkdir backend
cd backend

# Python ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate  # MacOS/Linux
# venv\Scripts\activate    # Windows
```

**Step 2: í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜**
```bash
# requirements.txt ìƒì„±
cat > requirements.txt << EOF
fastapi==0.104.1
uvicorn==0.24.0
langchain==0.0.340
langchain-community==0.0.20
langchain-openai==0.0.5
chromadb==0.4.18
sentence-transformers==2.2.2
pypdf2==3.0.1
pymupdf==1.23.8
requests==2.31.0
python-dotenv==1.0.0
pandas==2.1.4
numpy==1.24.3
scikit-learn==1.3.2
openai==1.3.8
anthropic==0.7.8
aiofiles==23.2.0
python-multipart==0.0.6
EOF

# íŒ¨í‚¤ì§€ ì¼ê´„ ì„¤ì¹˜
pip install -r requirements.txt
```

**ì‹¤í–‰ í™•ì¸:**
```bash
# ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ í™•ì¸
pip list

# Pythonì—ì„œ import í…ŒìŠ¤íŠ¸
python3 -c "import langchain; print('Langchain ì„¤ì¹˜ ì™„ë£Œ')"
python3 -c "import chromadb; print('ChromaDB ì„¤ì¹˜ ì™„ë£Œ')"
```

### 2.2 API í‚¤ ì„¤ì •

**Step 1: .env íŒŒì¼ ìƒì„±**
```bash
# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
cat > .env << EOF
# OpenAI API í‚¤
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude API í‚¤
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# í•œêµ­ íŠ¹í—ˆì²­ KIPRIS API í‚¤
KIPRIS_API_KEY=your_kipris_api_key_here

# USPTO API í‚¤ (í•„ìš”ì‹œ)
USPTO_API_KEY=your_uspto_api_key_here

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
VECTOR_DB_PATH=./data/vectordb
PDF_STORAGE_PATH=./data/pdfs
EOF
```

**Step 2: API í‚¤ ë°œê¸‰ ë°©ë²•**

**OpenAI API:**
1. [OpenAI Platform](https://platform.openai.com/) ì ‘ì†
2. ê³„ì • ìƒì„± ë° ë¡œê·¸ì¸
3. API Keys â†’ Create new secret key
4. ìƒì„±ëœ í‚¤ë¥¼ `.env` íŒŒì¼ì— ì…ë ¥

**KIPRIS API (í•œêµ­ íŠ¹í—ˆì²­):**
1. [KIPRIS](https://www.kipris.or.kr/) ì ‘ì†
2. íšŒì›ê°€ì… í›„ Open API ì‹ ì²­
3. ë°œê¸‰ë°›ì€ í‚¤ë¥¼ `.env` íŒŒì¼ì— ì…ë ¥

---

## 3. íŠ¹í—ˆì²­ API ì—°ë™

### 3.1 í•œêµ­ íŠ¹í—ˆì²­ KIPRIS API

**Step 1: API ì—°ë™ ëª¨ë“ˆ ìƒì„±**
```python
# backend/patent_search.py
import requests
import json
import os
from typing import List, Dict, Optional
from dotenv import load_dotenv

load_dotenv()

class KIPRISSearcher:
    def __init__(self):
        self.api_key = os.getenv('KIPRIS_API_KEY')
        self.base_url = 'http://plus.kipris.or.kr/openapi/rest/PatentSearchService'
        
    def search_patents(self, keyword: str, max_results: int = 10) -> List[Dict]:
        """
        KIPRIS APIë¥¼ í†µí•œ íŠ¹í—ˆ ê²€ìƒ‰
        """
        params = {
            'accessKey': self.api_key,
            'word': keyword,
            'target': 'title',  # title, abstract, claim
            'start': 1,
            'end': max_results,
            'sort': 'AD',  # AD: ì¶œì›ì¼ìˆœ, RD: ë“±ë¡ì¼ìˆœ
        }
        
        try:
            response = requests.get(f"{self.base_url}/search", params=params)
            response.raise_for_status()
            
            # XML ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜ (ì‹¤ì œ API ì‘ë‹µì— ë”°ë¼ ìˆ˜ì • í•„ìš”)
            data = response.json()
            return self.parse_kipris_response(data)
            
        except requests.exceptions.RequestException as e:
            print(f"KIPRIS API ì˜¤ë¥˜: {e}")
            return []
    
    def parse_kipris_response(self, data: Dict) -> List[Dict]:
        """
        KIPRIS ì‘ë‹µ ë°ì´í„° íŒŒì‹±
        """
        patents = []
        items = data.get('response', {}).get('body', {}).get('items', [])
        
        for item in items:
            patent = {
                'source': 'KIPRIS',
                'patent_number': item.get('applicationNumber'),
                'title': item.get('title'),
                'abstract': item.get('abstract'),
                'applicant': item.get('applicantName'),
                'application_date': item.get('applicationDate'),
                'registration_date': item.get('registrationDate'),
                'status': item.get('applicationStatus'),
                'classification': item.get('ipcNumber'),
                'url': item.get('url')
            }
            patents.append(patent)
        
        return patents

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    searcher = KIPRISSearcher()
    results = searcher.search_patents("ë°˜ë„ì²´ ê°€ìŠ¤ ì •í™”", max_results=5)
    
    for patent in results:
        print(f"íŠ¹í—ˆë²ˆí˜¸: {patent['patent_number']}")
        print(f"ì œëª©: {patent['title']}")
        print(f"ì¶œì›ì¸: {patent['applicant']}")
        print("-" * 50)
```

**ì‹¤í–‰ ë°©ë²•:**
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python3 patent_search.py
```

### 3.2 ë¯¸êµ­ íŠ¹í—ˆì²­ USPTO API

**Step 1: USPTO API ì—°ë™**
```python
# backend/uspto_search.py
import requests
import json
from typing import List, Dict

class USPTOSearcher:
    def __init__(self):
        self.base_url = 'https://developer.uspto.gov/api/v1'
    
    def search_patents(self, keyword: str, max_results: int = 10) -> List[Dict]:
        """
        USPTO APIë¥¼ í†µí•œ íŠ¹í—ˆ ê²€ìƒ‰
        """
        # USPTOì˜ ì‹¤ì œ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
        search_url = f"{self.base_url}/patent/search"
        
        params = {
            'q': keyword,
            'f': 'json',
            'o': max_results
        }
        
        try:
            response = requests.get(search_url, params=params)
            response.raise_for_status()
            
            data = response.json()
            return self.parse_uspto_response(data)
            
        except requests.exceptions.RequestException as e:
            print(f"USPTO API ì˜¤ë¥˜: {e}")
            return []
    
    def parse_uspto_response(self, data: Dict) -> List[Dict]:
        """
        USPTO ì‘ë‹µ ë°ì´í„° íŒŒì‹±
        """
        patents = []
        items = data.get('results', [])
        
        for item in items:
            patent = {
                'source': 'USPTO',
                'patent_number': item.get('patent_number'),
                'title': item.get('patent_title'),
                'abstract': item.get('abstract'),
                'assignee': item.get('assignee_organization'),
                'grant_date': item.get('patent_date'),
                'application_date': item.get('app_date'),
                'inventors': item.get('inventor_name_first', []),
                'classification': item.get('uspc_class'),
                'url': f"https://patents.uspto.gov/patent/{item.get('patent_number')}"
            }
            patents.append(patent)
        
        return patents

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    searcher = USPTOSearcher()
    results = searcher.search_patents("semiconductor gas purification", max_results=5)
    
    for patent in results:
        print(f"Patent: {patent['patent_number']}")
        print(f"Title: {patent['title']}")
        print(f"Assignee: {patent['assignee']}")
        print("-" * 50)
```

---

## 4. PDF ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ

### 4.1 PDF ì²˜ë¦¬ ëª¨ë“ˆ

**Step 1: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìƒì„±**
```python
# backend/pdf_processor.py
import os
import fitz  # PyMuPDF
import PyPDF2
from typing import Dict, List, Optional
from pathlib import Path

class PDFProcessor:
    def __init__(self, pdf_storage_path: str = "./data/pdfs"):
        self.pdf_storage_path = Path(pdf_storage_path)
        self.pdf_storage_path.mkdir(parents=True, exist_ok=True)
    
    def extract_text_pymupdf(self, pdf_path: str) -> Dict[str, str]:
        """
        PyMuPDFë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•œê¸€ ì§€ì› ìš°ìˆ˜)
        """
        try:
            doc = fitz.open(pdf_path)
            
            extracted_data = {
                'filename': os.path.basename(pdf_path),
                'full_text': '',
                'pages': []
            }
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text()
                
                extracted_data['pages'].append({
                    'page_number': page_num + 1,
                    'text': text
                })
                
                extracted_data['full_text'] += f"\\n--- í˜ì´ì§€ {page_num + 1} ---\\n{text}"
            
            doc.close()
            return extracted_data
            
        except Exception as e:
            print(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜ ({pdf_path}): {e}")
            return None
    
    def extract_patent_sections(self, text: str) -> Dict[str, str]:
        """
        íŠ¹í—ˆ ë¬¸ì„œì—ì„œ ì£¼ìš” ì„¹ì…˜ ì¶”ì¶œ
        """
        sections = {
            'title': '',
            'abstract': '',
            'claims': '',
            'detailed_description': '',
            'background': ''
        }
        
        # íŠ¹í—ˆ ì„¹ì…˜ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ
        keywords = {
            'abstract': ['ìš”ì•½', 'ABSTRACT', 'ë°œëª…ì˜ ìš”ì•½'],
            'claims': ['íŠ¹í—ˆì²­êµ¬ë²”ìœ„', 'CLAIMS', 'ì²­êµ¬í•­'],
            'detailed_description': ['ë°œëª…ì˜ ìƒì„¸í•œ ì„¤ëª…', 'DETAILED DESCRIPTION'],
            'background': ['ë°œëª…ì˜ ë°°ê²½', 'BACKGROUND', 'ì¢…ë˜ê¸°ìˆ ']
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì„¹ì…˜ ë¶„ë¦¬ (ê°œì„  í•„ìš”)
        lines = text.split('\\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì„¹ì…˜ í—¤ë” ê°ì§€
            for section, section_keywords in keywords.items():
                if any(keyword in line for keyword in section_keywords):
                    current_section = section
                    break
            
            # í˜„ì¬ ì„¹ì…˜ì— í…ìŠ¤íŠ¸ ì¶”ê°€
            if current_section:
                sections[current_section] += line + '\\n'
        
        return sections
    
    def process_patent_pdf(self, pdf_path: str) -> Dict:
        """
        íŠ¹í—ˆ PDF ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        """
        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        extracted_data = self.extract_text_pymupdf(pdf_path)
        if not extracted_data:
            return None
        
        # 2. ì„¹ì…˜ ë¶„ë¦¬
        sections = self.extract_patent_sections(extracted_data['full_text'])
        
        # 3. ë©”íƒ€ë°ì´í„° ì¶”ê°€
        result = {
            'filename': extracted_data['filename'],
            'full_text': extracted_data['full_text'],
            'sections': sections,
            'page_count': len(extracted_data['pages']),
            'file_path': pdf_path
        }
        
        return result

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    processor = PDFProcessor()
    
    # ìƒ˜í”Œ PDF íŒŒì¼ì´ ìˆë‹¤ë©´ í…ŒìŠ¤íŠ¸
    sample_pdf = "./data/pdfs/sample_patent.pdf"
    if os.path.exists(sample_pdf):
        result = processor.process_patent_pdf(sample_pdf)
        if result:
            print(f"íŒŒì¼: {result['filename']}")
            print(f"í˜ì´ì§€ ìˆ˜: {result['page_count']}")
            print(f"ìš”ì•½ ê¸¸ì´: {len(result['sections']['abstract'])}")
            print("\\n--- ìš”ì•½ ë¯¸ë¦¬ë³´ê¸° ---")
            print(result['sections']['abstract'][:200])
```

**ì‹¤í–‰ ë°©ë²•:**
```bash
# í…ŒìŠ¤íŠ¸ PDF íŒŒì¼ ì¤€ë¹„
mkdir -p data/pdfs

# PDF ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
python3 pdf_processor.py
```

### 4.2 PDF ì—…ë¡œë“œ API

**Step 1: FastAPI ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸**
```python
# backend/main.py
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import shutil
import os
from pdf_processor import PDFProcessor

app = FastAPI(title="GST Patent Analysis API")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

pdf_processor = PDFProcessor()

@app.post("/upload-pdf")
async def upload_patent_pdf(file: UploadFile = File(...)):
    """
    íŠ¹í—ˆ PDF ì—…ë¡œë“œ ë° ì²˜ë¦¬
    """
    if not file.filename.endswith('.pdf'):
        raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # íŒŒì¼ ì €ì¥
        file_path = f"./data/pdfs/{file.filename}"
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # PDF ì²˜ë¦¬
        result = pdf_processor.process_patent_pdf(file_path)
        
        if result:
            return {
                "status": "success",
                "message": "PDF ì²˜ë¦¬ ì™„ë£Œ",
                "data": result
            }
        else:
            raise HTTPException(status_code=500, detail="PDF ì²˜ë¦¬ ì‹¤íŒ¨")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

@app.get("/")
async def root():
    return {"message": "GST Patent Analysis API"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**ì„œë²„ ì‹¤í–‰:**
```bash
# FastAPI ì„œë²„ ì‹œì‘
python3 main.py

# ë˜ëŠ” uvicornìœ¼ë¡œ ì‹¤í–‰
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**í…ŒìŠ¤íŠ¸:**
```bash
# ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
open http://localhost:8000/docs
```

---

## 5. í…ìŠ¤íŠ¸ ì„ë² ë”© ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤

### 5.1 ì„ë² ë”© ëª¨ë¸ ì„¤ì •

**Step 1: ì„ë² ë”© í´ë˜ìŠ¤ ìƒì„±**
```python
# backend/embeddings.py
from sentence_transformers import SentenceTransformer
from langchain.embeddings import HuggingFaceEmbeddings
from typing import List, Dict
import numpy as np

class PatentEmbedding:
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        ë‹¤êµ­ì–´ ì§€ì› ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        - all-MiniLM-L6-v2: ì˜ì–´ íŠ¹í™”, ë¹ ë¥¸ ì†ë„
        - paraphrase-multilingual-MiniLM-L12-v2: ë‹¤êµ­ì–´ ì§€ì›
        - sentence-transformers/distiluse-base-multilingual-cased: í•œêµ­ì–´ ì§€ì›
        """
        self.model = SentenceTransformer(model_name)
        
    def get_korean_optimized_model(self):
        """
        í•œêµ­ì–´ ìµœì í™” ëª¨ë¸ë¡œ ë³€ê²½
        """
        self.model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased')
    
    def encode_text(self, text: str) -> np.ndarray:
        """
        í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©
        """
        return self.model.encode(text)
    
    def encode_batch(self, texts: List[str]) -> np.ndarray:
        """
        í…ìŠ¤íŠ¸ ë°°ì¹˜ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©
        """
        return self.model.encode(texts)
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """
        ë‘ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        """
        embedding1 = self.encode_text(text1)
        embedding2 = self.encode_text(text2)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = np.dot(embedding1, embedding2) / (
            np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
        )
        
        return float(similarity)

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    embedder = PatentEmbedding()
    
    # í•œêµ­ì–´ í…ŒìŠ¤íŠ¸
    text1 = "ë°˜ë„ì²´ ì œì¡° ê³µì •ì—ì„œ ìœ í•´ê°€ìŠ¤ë¥¼ ì œê±°í•˜ëŠ” ê¸°ìˆ "
    text2 = "ë°˜ë„ì²´ ìƒì‚° ê³¼ì •ì˜ ë…ì„± ê°€ìŠ¤ ì •í™” ë°©ë²•"
    
    similarity = embedder.calculate_similarity(text1, text2)
    print(f"ìœ ì‚¬ë„: {similarity:.4f}")
    
    # ì„ë² ë”© í…ŒìŠ¤íŠ¸
    embedding = embedder.encode_text(text1)
    print(f"ì„ë² ë”© ì°¨ì›: {embedding.shape}")
```

### 5.2 ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

**Step 1: ë²¡í„° DB í´ë˜ìŠ¤ ìƒì„±**
```python
# backend/vector_database.py
import chromadb
from chromadb.config import Settings
import uuid
from typing import List, Dict, Optional
from embeddings import PatentEmbedding

class PatentVectorDB:
    def __init__(self, persist_directory: str = "./data/vectordb"):
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        # íŠ¹í—ˆ ì»¬ë ‰ì…˜ ìƒì„±/ì—°ê²°
        self.collection = self.client.get_or_create_collection(
            name="patents",
            metadata={"description": "GST Patent Analysis Collection"}
        )
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedder = PatentEmbedding()
        self.embedder.get_korean_optimized_model()  # í•œêµ­ì–´ ìµœì í™”
    
    def add_patent(self, patent_data: Dict) -> str:
        """
        íŠ¹í—ˆ ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì¶”ê°€
        """
        # ê³ ìœ  ID ìƒì„±
        patent_id = str(uuid.uuid4())
        
        # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¡°í•© (ì œëª© + ìš”ì•½ + ì£¼ìš” ë‚´ìš©)
        search_text = f"{patent_data.get('title', '')} {patent_data.get('abstract', '')} {patent_data.get('claims', '')}"
        
        # ì„ë² ë”© ìƒì„±
        embedding = self.embedder.encode_text(search_text)
        
        # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        metadata = {
            'patent_number': patent_data.get('patent_number', ''),
            'title': patent_data.get('title', ''),
            'source': patent_data.get('source', 'GST'),
            'application_date': patent_data.get('application_date', ''),
            'status': patent_data.get('status', 'active'),
            'file_path': patent_data.get('file_path', '')
        }
        
        # ë²¡í„° DBì— ì¶”ê°€
        self.collection.add(
            embeddings=[embedding.tolist()],
            documents=[search_text],
            metadatas=[metadata],
            ids=[patent_id]
        )
        
        return patent_id
    
    def search_similar_patents(self, query_text: str, top_k: int = 5) -> List[Dict]:
        """
        ìœ ì‚¬í•œ íŠ¹í—ˆ ê²€ìƒ‰
        """
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedder.encode_text(query_text)
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k
        )
        
        # ê²°ê³¼ íŒŒì‹±
        similar_patents = []
        for i in range(len(results['ids'][0])):
            patent = {
                'id': results['ids'][0][i],
                'similarity_score': 1 - results['distances'][0][i],  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                'metadata': results['metadatas'][0][i],
                'content': results['documents'][0][i][:200]  # ë¯¸ë¦¬ë³´ê¸°
            }
            similar_patents.append(patent)
        
        return similar_patents
    
    def get_collection_stats(self) -> Dict:
        """
        ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´
        """
        count = self.collection.count()
        return {
            'total_patents': count,
            'collection_name': self.collection.name
        }

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    vector_db = PatentVectorDB()
    
    # ìƒ˜í”Œ íŠ¹í—ˆ ë°ì´í„° ì¶”ê°€
    sample_patent = {
        'patent_number': '10-TEST-001',
        'title': 'ë°˜ë„ì²´ ì›¨ì´í¼ ê°€ìŠ¤ ì •í™” ì‹œìŠ¤í…œ',
        'abstract': 'ë°˜ë„ì²´ ì œì¡° ê³µì •ì—ì„œ ë°œìƒí•˜ëŠ” ìœ í•´ê°€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì œê±°í•˜ëŠ” ì •í™” ì‹œìŠ¤í…œ',
        'claims': 'ì›¨ì´í¼ ì²˜ë¦¬ ì±”ë²„ì™€ ì—°ê²°ëœ ê°€ìŠ¤ ì •í™” ì¥ì¹˜',
        'source': 'GST',
        'status': 'active'
    }
    
    # íŠ¹í—ˆ ì¶”ê°€
    patent_id = vector_db.add_patent(sample_patent)
    print(f"íŠ¹í—ˆ ì¶”ê°€ë¨: {patent_id}")
    
    # ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰
    query = "ë°˜ë„ì²´ ê°€ìŠ¤ ì²˜ë¦¬ ê¸°ìˆ "
    similar = vector_db.search_similar_patents(query, top_k=3)
    
    print(f"\\n'{query}' ê²€ìƒ‰ ê²°ê³¼:")
    for patent in similar:
        print(f"ìœ ì‚¬ë„: {patent['similarity_score']:.4f}")
        print(f"ì œëª©: {patent['metadata']['title']}")
        print("-" * 40)
```

**ì‹¤í–‰ ë°©ë²•:**
```bash
# ë²¡í„° DB í…ŒìŠ¤íŠ¸
python3 vector_database.py
```

---

## 6. ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ

### 6.1 í†µí•© ê²€ìƒ‰ API

**Step 1: í†µí•© ê²€ìƒ‰ ì„œë¹„ìŠ¤**
```python
# backend/patent_analyzer.py
from typing import List, Dict, Optional
from patent_search import KIPRISSearcher, USPTOSearcher
from vector_database import PatentVectorDB
from pdf_processor import PDFProcessor
import asyncio

class PatentAnalyzer:
    def __init__(self):
        self.kipris = KIPRISSearcher()
        self.uspto = USPTOSearcher()
        self.vector_db = PatentVectorDB()
        self.pdf_processor = PDFProcessor()
    
    async def comprehensive_search(self, query: str, include_external: bool = True) -> Dict:
        """
        í¬ê´„ì  íŠ¹í—ˆ ê²€ìƒ‰ (ë‚´ë¶€ DB + ì™¸ë¶€ API)
        """
        results = {
            'query': query,
            'internal_results': [],
            'kipris_results': [],
            'uspto_results': [],
            'analysis': {}
        }
        
        # 1. ë‚´ë¶€ ë²¡í„° DB ê²€ìƒ‰
        internal_results = self.vector_db.search_similar_patents(query, top_k=10)
        results['internal_results'] = internal_results
        
        if include_external:
            # 2. ì™¸ë¶€ API ë³‘ë ¬ ê²€ìƒ‰
            tasks = [
                asyncio.create_task(self._search_kipris_async(query)),
                asyncio.create_task(self._search_uspto_async(query))
            ]
            
            kipris_results, uspto_results = await asyncio.gather(*tasks)
            results['kipris_results'] = kipris_results
            results['uspto_results'] = uspto_results
        
        # 3. ê²°ê³¼ ë¶„ì„
        results['analysis'] = self._analyze_search_results(results)
        
        return results
    
    async def _search_kipris_async(self, query: str) -> List[Dict]:
        """
        ë¹„ë™ê¸° KIPRIS ê²€ìƒ‰
        """
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.kipris.search_patents, query, 5)
    
    async def _search_uspto_async(self, query: str) -> List[Dict]:
        """
        ë¹„ë™ê¸° USPTO ê²€ìƒ‰
        """
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.uspto.search_patents, query, 5)
    
    def _analyze_search_results(self, results: Dict) -> Dict:
        """
        ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
        """
        analysis = {
            'total_found': 0,
            'high_similarity_count': 0,
            'technology_keywords': [],
            'recommendation': ''
        }
        
        # ë‚´ë¶€ ê²°ê³¼ ë¶„ì„
        internal_count = len(results['internal_results'])
        high_similarity = len([r for r in results['internal_results'] if r['similarity_score'] > 0.7])
        
        analysis['total_found'] = internal_count + len(results['kipris_results']) + len(results['uspto_results'])
        analysis['high_similarity_count'] = high_similarity
        
        # ì¶”ì²œ ìƒì„±
        if high_similarity > 3:
            analysis['recommendation'] = "ìœ ì‚¬í•œ ê¸°ìˆ ì˜ íŠ¹í—ˆê°€ ë‹¤ìˆ˜ ì¡´ì¬í•©ë‹ˆë‹¤. ì°¨ë³„í™” ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif high_similarity > 0:
            analysis['recommendation'] = "ì¼ë¶€ ìœ ì‚¬ íŠ¹í—ˆê°€ ì¡´ì¬í•˜ë‚˜ ê°œì„  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
        else:
            analysis['recommendation'] = "ì‹ ê·œ ê¸°ìˆ  ì˜ì—­ìœ¼ë¡œ íŠ¹í—ˆ ì¶œì›ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return analysis
    
    def compare_patents(self, patent1_id: str, patent2_id: str) -> Dict:
        """
        ë‘ íŠ¹í—ˆ ê°„ ìƒì„¸ ë¹„êµ
        """
        # ë²¡í„° DBì—ì„œ íŠ¹í—ˆ ì •ë³´ ì¡°íšŒ
        # (ì‹¤ì œ êµ¬í˜„ì‹œ get_patent_by_id ë©”ì†Œë“œ í•„ìš”)
        
        comparison = {
            'patent1_id': patent1_id,
            'patent2_id': patent2_id,
            'similarity_score': 0.0,
            'common_keywords': [],
            'differences': [],
            'recommendation': ''
        }
        
        # ë¹„êµ ë¡œì§ êµ¬í˜„
        # ...
        
        return comparison

# FastAPIì— í†µí•©
from main import app

analyzer = PatentAnalyzer()

@app.post("/search-patents")
async def search_patents(request: Dict):
    """
    í†µí•© íŠ¹í—ˆ ê²€ìƒ‰ API
    """
    query = request.get('query', '')
    include_external = request.get('include_external', True)
    
    if not query:
        raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    try:
        results = await analyzer.comprehensive_search(query, include_external)
        return results
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

@app.post("/compare-patents")
async def compare_patents(request: Dict):
    """
    íŠ¹í—ˆ ë¹„êµ API
    """
    patent1_id = request.get('patent1_id')
    patent2_id = request.get('patent2_id')
    
    if not patent1_id or not patent2_id:
        raise HTTPException(status_code=400, detail="ë¹„êµí•  íŠ¹í—ˆ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    try:
        comparison = analyzer.compare_patents(patent1_id, patent2_id)
        return comparison
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¹„êµ ì˜¤ë¥˜: {str(e)}")
```

**ì‹¤í–‰ ë°©ë²•:**
```bash
# ì„œë²„ ì¬ì‹œì‘
uvicorn main:app --reload

# API í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8000/search-patents" \\
-H "Content-Type: application/json" \\
-d '{"query": "ë°˜ë„ì²´ ê°€ìŠ¤ ì •í™”", "include_external": true}'
```

---

## 7. ì–¸ì–´ëª¨ë¸ í†µí•©

### 7.1 LLM ë¶„ì„ ëª¨ë“ˆ

**Step 1: LangChain LLM í†µí•©**
```python
# backend/llm_analyzer.py
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from typing import Dict, List
import os

class PatentLLMAnalyzer:
    def __init__(self):
        self.llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0.3,
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )
        
        # íŠ¹í—ˆ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤
        self.setup_prompts()
    
    def setup_prompts(self):
        """
        íŠ¹í—ˆ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        """
        # ê¸°ìˆ  ë¶„ì„ í”„ë¡¬í”„íŠ¸
        self.tech_analysis_prompt = PromptTemplate(
            input_variables=["patent_title", "patent_abstract", "patent_claims"],
            template="""
ë‹¤ìŒ íŠ¹í—ˆì˜ ê¸°ìˆ ì  íŠ¹ì§•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì œëª©: {patent_title}
ìš”ì•½: {patent_abstract}
ì£¼ìš” ì²­êµ¬í•­: {patent_claims}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. í•µì‹¬ ê¸°ìˆ  ìš”ì†Œ
2. ê¸°ìˆ ì˜ í˜ì‹ ì„±
3. ìƒìš©í™” ê°€ëŠ¥ì„±
4. ìœ ì‚¬ ê¸°ìˆ  ëŒ€ë¹„ ì°¨ë³„ì 
5. íŠ¹í—ˆ ê°•ë„ í‰ê°€ (1-10ì )

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        )
        
        # ìœ ì‚¬ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        self.similarity_prompt = PromptTemplate(
            input_variables=["patent1", "patent2"],
            template="""
ë‹¤ìŒ ë‘ íŠ¹í—ˆì˜ ìœ ì‚¬ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

íŠ¹í—ˆ 1: {patent1}
íŠ¹í—ˆ 2: {patent2}

ë¶„ì„ í•­ëª©:
1. ê¸°ìˆ ì  ìœ ì‚¬ì„± (1-10ì )
2. ì²­êµ¬ë²”ìœ„ ê²¹ì¹¨ ì •ë„
3. íšŒí”¼ ì„¤ê³„ ê°€ëŠ¥ì„±
4. ì¹¨í•´ ìœ„í—˜ë„
5. ì°¨ë³„í™” ë°©ì•ˆ ì œì•ˆ

í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        )
        
        # íŠ¹í—ˆ ì „ëµ í”„ë¡¬í”„íŠ¸
        self.strategy_prompt = PromptTemplate(
            input_variables=["technology_area", "competitor_patents", "our_patents"],
            template="""
ë‹¤ìŒ ê¸°ìˆ  ë¶„ì•¼ì—ì„œì˜ íŠ¹í—ˆ ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:

ê¸°ìˆ  ë¶„ì•¼: {technology_area}
ê²½ìŸì‚¬ íŠ¹í—ˆ í˜„í™©: {competitor_patents}
ë³´ìœ  íŠ¹í—ˆ í˜„í™©: {our_patents}

ì „ëµ ìˆ˜ë¦½:
1. íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ê°•í™” ë°©ì•ˆ
2. ê¸°ìˆ  ê°œë°œ ë°©í–¥ ì œì•ˆ
3. íŠ¹í—ˆ ì¶œì› ìš°ì„ ìˆœìœ„
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆ
5. ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš

êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì„ í•œêµ­ì–´ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.
"""
        )
    
    async def analyze_patent_technology(self, patent_data: Dict) -> Dict:
        """
        íŠ¹í—ˆ ê¸°ìˆ  ë¶„ì„
        """
        chain = LLMChain(llm=self.llm, prompt=self.tech_analysis_prompt)
        
        try:
            result = await chain.arun(
                patent_title=patent_data.get('title', ''),
                patent_abstract=patent_data.get('abstract', ''),
                patent_claims=patent_data.get('claims', '')
            )
            
            return {
                'patent_id': patent_data.get('id'),
                'analysis': result,
                'analysis_type': 'technology_analysis'
            }
            
        except Exception as e:
            return {
                'error': f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                'analysis_type': 'technology_analysis'
            }
    
    async def compare_patent_similarity(self, patent1: Dict, patent2: Dict) -> Dict:
        """
        íŠ¹í—ˆ ìœ ì‚¬ì„± ë¶„ì„
        """
        chain = LLMChain(llm=self.llm, prompt=self.similarity_prompt)
        
        patent1_text = f"ì œëª©: {patent1.get('title', '')}\\nìš”ì•½: {patent1.get('abstract', '')}"
        patent2_text = f"ì œëª©: {patent2.get('title', '')}\\nìš”ì•½: {patent2.get('abstract', '')}"
        
        try:
            result = await chain.arun(
                patent1=patent1_text,
                patent2=patent2_text
            )
            
            return {
                'patent1_id': patent1.get('id'),
                'patent2_id': patent2.get('id'),
                'similarity_analysis': result,
                'analysis_type': 'similarity_analysis'
            }
            
        except Exception as e:
            return {
                'error': f"ë¹„êµ ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                'analysis_type': 'similarity_analysis'
            }
    
    async def generate_patent_strategy(self, technology_area: str, 
                                     competitor_patents: List[Dict], 
                                     our_patents: List[Dict]) -> Dict:
        """
        íŠ¹í—ˆ ì „ëµ ìˆ˜ë¦½
        """
        chain = LLMChain(llm=self.llm, prompt=self.strategy_prompt)
        
        # ê²½ìŸì‚¬ íŠ¹í—ˆ ìš”ì•½
        competitor_summary = "\\n".join([
            f"- {p.get('title', '')} ({p.get('patent_number', '')})"
            for p in competitor_patents[:5]
        ])
        
        # ë³´ìœ  íŠ¹í—ˆ ìš”ì•½
        our_summary = "\\n".join([
            f"- {p.get('title', '')} ({p.get('patent_number', '')})"
            for p in our_patents[:5]
        ])
        
        try:
            result = await chain.arun(
                technology_area=technology_area,
                competitor_patents=competitor_summary,
                our_patents=our_summary
            )
            
            return {
                'technology_area': technology_area,
                'strategy': result,
                'analysis_type': 'patent_strategy'
            }
            
        except Exception as e:
            return {
                'error': f"ì „ëµ ìˆ˜ë¦½ ì˜¤ë¥˜: {str(e)}",
                'analysis_type': 'patent_strategy'
            }

# FastAPIì— í†µí•©
llm_analyzer = PatentLLMAnalyzer()

@app.post("/analyze-patent")
async def analyze_patent(request: Dict):
    """
    íŠ¹í—ˆ ê¸°ìˆ  ë¶„ì„ API
    """
    patent_data = request.get('patent_data')
    
    if not patent_data:
        raise HTTPException(status_code=400, detail="íŠ¹í—ˆ ë°ì´í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.")
    
    try:
        analysis = await llm_analyzer.analyze_patent_technology(patent_data)
        return analysis
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

@app.post("/generate-strategy")
async def generate_strategy(request: Dict):
    """
    íŠ¹í—ˆ ì „ëµ ìˆ˜ë¦½ API
    """
    technology_area = request.get('technology_area')
    competitor_patents = request.get('competitor_patents', [])
    our_patents = request.get('our_patents', [])
    
    try:
        strategy = await llm_analyzer.generate_patent_strategy(
            technology_area, competitor_patents, our_patents
        )
        return strategy
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì „ëµ ìˆ˜ë¦½ ì˜¤ë¥˜: {str(e)}")
```

**ì‹¤í–‰ í…ŒìŠ¤íŠ¸:**
```bash
# API í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8000/analyze-patent" \\
-H "Content-Type: application/json" \\
-d '{
    "patent_data": {
        "title": "ë°˜ë„ì²´ ê°€ìŠ¤ ì •í™” ì‹œìŠ¤í…œ",
        "abstract": "ë°˜ë„ì²´ ì œì¡° ê³µì •ì—ì„œ ë°œìƒí•˜ëŠ” ìœ í•´ê°€ìŠ¤ë¥¼ ì œê±°í•˜ëŠ” ì‹œìŠ¤í…œ",
        "claims": "ê°€ìŠ¤ ì •í™” ì±”ë²„ì™€ í•„í„°ë§ ëª¨ë“ˆì„ í¬í•¨í•˜ëŠ” ì‹œìŠ¤í…œ"
    }
}'
```

---

## 8. ì›¹ ì¸í„°í˜ì´ìŠ¤ ì—°ë™

### 8.1 í”„ë¡ íŠ¸ì—”ë“œ API ì—°ë™

**Step 1: JavaScript API í´ë¼ì´ì–¸íŠ¸**
```javascript
// frontend/js/patent-ai.js
class PatentAIClient {
    constructor() {
        this.apiBase = 'http://localhost:8000';
    }
    
    async searchPatents(query, includeExternal = true) {
        try {
            const response = await fetch(`${this.apiBase}/search-patents`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    query: query,
                    include_external: includeExternal
                })
            });
            
            return await response.json();
        } catch (error) {
            console.error('íŠ¹í—ˆ ê²€ìƒ‰ ì˜¤ë¥˜:', error);
            throw error;
        }
    }
    
    async uploadPatentPDF(file) {
        try {
            const formData = new FormData();
            formData.append('file', file);
            
            const response = await fetch(`${this.apiBase}/upload-pdf`, {
                method: 'POST',
                body: formData
            });
            
            return await response.json();
        } catch (error) {
            console.error('PDF ì—…ë¡œë“œ ì˜¤ë¥˜:', error);
            throw error;
        }
    }
    
    async analyzePatent(patentData) {
        try {
            const response = await fetch(`${this.apiBase}/analyze-patent`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    patent_data: patentData
                })
            });
            
            return await response.json();
        } catch (error) {
            console.error('íŠ¹í—ˆ ë¶„ì„ ì˜¤ë¥˜:', error);
            throw error;
        }
    }
    
    async generateStrategy(technologyArea, competitorPatents, ourPatents) {
        try {
            const response = await fetch(`${this.apiBase}/generate-strategy`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    technology_area: technologyArea,
                    competitor_patents: competitorPatents,
                    our_patents: ourPatents
                })
            });
            
            return await response.json();
        } catch (error) {
            console.error('ì „ëµ ìˆ˜ë¦½ ì˜¤ë¥˜:', error);
            throw error;
        }
    }
}

// ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
const patentAI = new PatentAIClient();

// AI ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
async function performAISearch() {
    const query = document.getElementById('ai-search-input').value;
    if (!query) {
        alert('ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
        return;
    }
    
    try {
        showLoadingSpinner();
        
        const results = await patentAI.searchPatents(query, true);
        displayAISearchResults(results);
        
    } catch (error) {
        alert('ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + error.message);
    } finally {
        hideLoadingSpinner();
    }
}

function displayAISearchResults(results) {
    const container = document.getElementById('ai-search-results');
    
    let html = `
        <div class="ai-search-summary">
            <h3>ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½</h3>
            <p>ì´ ${results.analysis.total_found}ê°œì˜ íŠ¹í—ˆë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.</p>
            <p>ë†’ì€ ìœ ì‚¬ë„ íŠ¹í—ˆ: ${results.analysis.high_similarity_count}ê°œ</p>
            <div class="recommendation">
                <strong>ì¶”ì²œ:</strong> ${results.analysis.recommendation}
            </div>
        </div>
        
        <div class="search-results-tabs">
            <button onclick="showResultTab('internal')" class="tab-button active">ë³´ìœ  íŠ¹í—ˆ</button>
            <button onclick="showResultTab('kipris')" class="tab-button">í•œêµ­ íŠ¹í—ˆì²­</button>
            <button onclick="showResultTab('uspto')" class="tab-button">ë¯¸êµ­ íŠ¹í—ˆì²­</button>
        </div>
    `;
    
    // ë‚´ë¶€ íŠ¹í—ˆ ê²°ê³¼
    html += '<div id="internal-results" class="result-tab active">';
    results.internal_results.forEach(patent => {
        html += `
            <div class="patent-result-card">
                <div class="similarity-score">ìœ ì‚¬ë„: ${(patent.similarity_score * 100).toFixed(1)}%</div>
                <h4>${patent.metadata.title}</h4>
                <p>íŠ¹í—ˆë²ˆí˜¸: ${patent.metadata.patent_number}</p>
                <p>${patent.content}</p>
                <button onclick="analyzePatentDetail('${patent.id}')">ìƒì„¸ ë¶„ì„</button>
            </div>
        `;
    });
    html += '</div>';
    
    // KIPRIS ê²°ê³¼
    html += '<div id="kipris-results" class="result-tab" style="display: none;">';
    results.kipris_results.forEach(patent => {
        html += `
            <div class="patent-result-card">
                <h4>${patent.title}</h4>
                <p>ì¶œì›ë²ˆí˜¸: ${patent.patent_number}</p>
                <p>ì¶œì›ì¸: ${patent.applicant}</p>
                <p>${patent.abstract}</p>
            </div>
        `;
    });
    html += '</div>';
    
    // USPTO ê²°ê³¼
    html += '<div id="uspto-results" class="result-tab" style="display: none;">';
    results.uspto_results.forEach(patent => {
        html += `
            <div class="patent-result-card">
                <h4>${patent.title}</h4>
                <p>íŠ¹í—ˆë²ˆí˜¸: ${patent.patent_number}</p>
                <p>ì–‘ìˆ˜ì¸: ${patent.assignee}</p>
                <p>${patent.abstract}</p>
            </div>
        `;
    });
    html += '</div>';
    
    container.innerHTML = html;
}

function showResultTab(tabName) {
    // ëª¨ë“  íƒ­ ìˆ¨ê¸°ê¸°
    document.querySelectorAll('.result-tab').forEach(tab => {
        tab.style.display = 'none';
    });
    
    // íƒ­ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì´ˆê¸°í™”
    document.querySelectorAll('.tab-button').forEach(btn => {
        btn.classList.remove('active');
    });
    
    // ì„ íƒëœ íƒ­ ë³´ì´ê¸°
    document.getElementById(`${tabName}-results`).style.display = 'block';
    event.target.classList.add('active');
}

async function analyzePatentDetail(patentId) {
    try {
        showLoadingSpinner();
        
        // íŠ¹í—ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œë¡œëŠ” APIì—ì„œ)
        const patentData = {
            id: patentId,
            title: "ìƒ˜í”Œ íŠ¹í—ˆ ì œëª©",
            abstract: "ìƒ˜í”Œ íŠ¹í—ˆ ìš”ì•½",
            claims: "ìƒ˜í”Œ íŠ¹í—ˆ ì²­êµ¬í•­"
        };
        
        const analysis = await patentAI.analyzePatent(patentData);
        displayPatentAnalysis(analysis);
        
    } catch (error) {
        alert('ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + error.message);
    } finally {
        hideLoadingSpinner();
    }
}

function displayPatentAnalysis(analysis) {
    const modal = document.createElement('div');
    modal.className = 'analysis-modal';
    modal.innerHTML = `
        <div class="modal-content">
            <div class="modal-header">
                <h3>AI íŠ¹í—ˆ ë¶„ì„ ê²°ê³¼</h3>
                <button onclick="closeAnalysisModal()" class="close-btn">&times;</button>
            </div>
            <div class="modal-body">
                <div class="analysis-content">
                    ${analysis.analysis.replace(/\\n/g, '<br>')}
                </div>
            </div>
        </div>
    `;
    
    document.body.appendChild(modal);
}

function closeAnalysisModal() {
    const modal = document.querySelector('.analysis-modal');
    if (modal) {
        modal.remove();
    }
}

// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
function showLoadingSpinner() {
    const spinner = document.createElement('div');
    spinner.id = 'loading-spinner';
    spinner.innerHTML = '<div class="spinner"></div><p>AI ë¶„ì„ ì¤‘...</p>';
    document.body.appendChild(spinner);
}

function hideLoadingSpinner() {
    const spinner = document.getElementById('loading-spinner');
    if (spinner) {
        spinner.remove();
    }
}
```

**Step 2: HTMLì— AI ê¸°ëŠ¥ ì¶”ê°€**
```html
<!-- index.htmlì— AI ê²€ìƒ‰ ì„¹ì…˜ ì¶”ê°€ -->
<section id="ai-analysis" class="mb-20 clearfix">
    <h2 class="text-3xl font-semibold text-gst-dark mb-8 flex items-center">
        <i class="fas fa-robot mr-3 text-gst-blue"></i>
        AI íŠ¹í—ˆ ë¶„ì„
    </h2>
    
    <div class="bg-white rounded-lg shadow-lg p-6">
        <!-- AI ê²€ìƒ‰ ì…ë ¥ -->
        <div class="ai-search-section mb-6">
            <h3 class="text-xl font-semibold mb-4">ğŸ” í†µí•© íŠ¹í—ˆ ê²€ìƒ‰</h3>
            <div class="flex gap-4">
                <input 
                    type="text" 
                    id="ai-search-input" 
                    placeholder="ì˜ˆ: ë°˜ë„ì²´ ê°€ìŠ¤ ì •í™” ê¸°ìˆ " 
                    class="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500"
                >
                <button 
                    onclick="performAISearch()" 
                    class="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors"
                >
                    AI ê²€ìƒ‰
                </button>
            </div>
        </div>
        
        <!-- PDF ì—…ë¡œë“œ -->
        <div class="pdf-upload-section mb-6">
            <h3 class="text-xl font-semibold mb-4">ğŸ“„ íŠ¹í—ˆ PDF ë¶„ì„</h3>
            <div class="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center">
                <input type="file" id="pdf-upload" accept=".pdf" style="display: none" onchange="handlePDFUpload(event)">
                <button onclick="document.getElementById('pdf-upload').click()" class="px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700">
                    PDF ì—…ë¡œë“œ
                </button>
                <p class="mt-2 text-gray-600">íŠ¹í—ˆ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ AI ë¶„ì„ì„ ë°›ì•„ë³´ì„¸ìš”</p>
            </div>
        </div>
        
        <!-- ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ì˜ì—­ -->
        <div id="ai-search-results"></div>
    </div>
</section>

<script src="js/patent-ai.js"></script>
```

**Step 3: CSS ìŠ¤íƒ€ì¼ ì¶”ê°€**
```css
/* css/style.cssì— ì¶”ê°€ */

/* AI ë¶„ì„ ì„¹ì…˜ */
#ai-analysis {
    background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
    padding: 2rem;
    border-radius: 15px;
}

.ai-search-section {
    background: white;
    padding: 1.5rem;
    border-radius: 10px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

.pdf-upload-section {
    background: white;
    padding: 1.5rem;
    border-radius: 10px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

/* ê²€ìƒ‰ ê²°ê³¼ ìŠ¤íƒ€ì¼ */
.ai-search-summary {
    background: #f8fafc;
    padding: 1rem;
    border-radius: 8px;
    margin-bottom: 1rem;
}

.recommendation {
    background: #dbeafe;
    padding: 0.75rem;
    border-radius: 6px;
    margin-top: 0.5rem;
    border-left: 4px solid #3b82f6;
}

.search-results-tabs {
    display: flex;
    gap: 0.5rem;
    margin-bottom: 1rem;
}

.tab-button {
    padding: 0.5rem 1rem;
    border: none;
    background: #e5e7eb;
    border-radius: 6px;
    cursor: pointer;
    transition: all 0.3s;
}

.tab-button.active {
    background: #3b82f6;
    color: white;
}

.patent-result-card {
    background: white;
    border: 1px solid #e5e7eb;
    border-radius: 8px;
    padding: 1rem;
    margin-bottom: 1rem;
    position: relative;
}

.similarity-score {
    position: absolute;
    top: 1rem;
    right: 1rem;
    background: #10b981;
    color: white;
    padding: 0.25rem 0.5rem;
    border-radius: 4px;
    font-size: 0.875rem;
}

/* ë¶„ì„ ëª¨ë‹¬ */
.analysis-modal {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0,0,0,0.5);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
}

.modal-content {
    background: white;
    border-radius: 10px;
    max-width: 800px;
    width: 90%;
    max-height: 80%;
    overflow-y: auto;
}

.modal-header {
    padding: 1rem;
    border-bottom: 1px solid #e5e7eb;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.modal-body {
    padding: 1.5rem;
}

.analysis-content {
    line-height: 1.6;
    color: #374151;
}

/* ë¡œë”© ìŠ¤í”¼ë„ˆ */
#loading-spinner {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(255,255,255,0.9);
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    z-index: 1001;
}

.spinner {
    width: 50px;
    height: 50px;
    border: 5px solid #f3f4f6;
    border-top: 5px solid #3b82f6;
    border-radius: 50%;
    animation: spin 1s linear infinite;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}
```

---

## 9. ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### 9.1 ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

**Step 1: í™˜ê²½ ì„¤ì • í™•ì¸**
```bash
# 1. ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# 2. í™˜ê²½ë³€ìˆ˜ í™•ì¸
cat .env

# 3. í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p data/vectordb data/pdfs

# 4. ì„œë²„ ì‹œì‘
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Step 2: ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸**
```python
# test_system.py
import asyncio
from patent_analyzer import PatentAnalyzer
from vector_database import PatentVectorDB
from llm_analyzer import PatentLLMAnalyzer

async def test_full_system():
    """
    ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
    """
    print("ğŸš€ GST íŠ¹í—ˆ AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # 1. ë²¡í„° DB í…ŒìŠ¤íŠ¸
    print("\\n1. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸...")
    vector_db = PatentVectorDB()
    
    sample_patent = {
        'patent_number': '10-TEST-001',
        'title': 'ë°˜ë„ì²´ ì›¨ì´í¼ ì²˜ë¦¬ìš© ê°€ìŠ¤ ì •í™” ì‹œìŠ¤í…œ',
        'abstract': 'ë°˜ë„ì²´ ì œì¡° ê³µì •ì—ì„œ ë°œìƒí•˜ëŠ” ë…ì„± ê°€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì œê±°í•˜ëŠ” ì •í™” ì‹œìŠ¤í…œ',
        'claims': 'ì›¨ì´í¼ ì²˜ë¦¬ ì±”ë²„, ê°€ìŠ¤ ì •í™” ëª¨ë“ˆ, ì œì–´ ì‹œìŠ¤í…œì„ í¬í•¨í•˜ëŠ” ì¥ì¹˜'
    }
    
    patent_id = vector_db.add_patent(sample_patent)
    print(f"âœ… íŠ¹í—ˆ ì¶”ê°€ ì™„ë£Œ: {patent_id}")
    
    # 2. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\\n2. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    similar_patents = vector_db.search_similar_patents("ë°˜ë„ì²´ ê°€ìŠ¤ ì²˜ë¦¬", top_k=3)
    for patent in similar_patents:
        print(f"  - ìœ ì‚¬ë„: {patent['similarity_score']:.3f}, ì œëª©: {patent['metadata']['title']}")
    
    # 3. LLM ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\\n3. AI ë¶„ì„ í…ŒìŠ¤íŠ¸...")
    llm_analyzer = PatentLLMAnalyzer()
    
    analysis_result = await llm_analyzer.analyze_patent_technology(sample_patent)
    print(f"âœ… AI ë¶„ì„ ì™„ë£Œ")
    print(f"ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: {analysis_result.get('analysis', '')[:100]}...")
    
    # 4. í†µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\\n4. í†µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    analyzer = PatentAnalyzer()
    
    search_results = await analyzer.comprehensive_search("ë°˜ë„ì²´ ê°€ìŠ¤", include_external=False)
    print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ")
    print(f"ë‚´ë¶€ íŠ¹í—ˆ ê²€ìƒ‰ ê²°ê³¼: {len(search_results['internal_results'])}ê±´")
    print(f"AI ì¶”ì²œ: {search_results['analysis']['recommendation']}")
    
    print("\\nğŸ‰ ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(test_full_system())
```

**ì‹¤í–‰:**
```bash
python3 test_system.py
```

### 9.2 ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

**ì‹œë‚˜ë¦¬ì˜¤ 1: ìƒˆë¡œìš´ ê¸°ìˆ  íŠ¹í—ˆì„± ê²€í† **
```bash
# 1. ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ "ë°˜ë„ì²´ ë‚˜ë…¸ì…ì í•„í„°ë§" ê²€ìƒ‰
# 2. AIê°€ êµ­ë‚´ì™¸ ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰
# 3. ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ ì œì‹œ
# 4. íŠ¹í—ˆ ì¶œì› ì „ëµ ì œì•ˆ
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: ê²½ìŸì‚¬ íŠ¹í—ˆ ë¶„ì„**
```bash
# 1. ê²½ìŸì‚¬ íŠ¹í—ˆ PDF ì—…ë¡œë“œ
# 2. AIê°€ ê¸°ìˆ ì  íŠ¹ì§• ë¶„ì„
# 3. ë³´ìœ  íŠ¹í—ˆì™€ ìœ ì‚¬ë„ ë¹„êµ
# 4. íšŒí”¼ ì„¤ê³„ ë°©ì•ˆ ì œì‹œ
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ ìˆ˜ë¦½**
```bash
# 1. ê¸°ìˆ  ë¶„ì•¼ "ê°€ìŠ¤ ì •í™”" ì…ë ¥
# 2. AIê°€ ì „ì²´ íŠ¹í—ˆ ì§€í˜• ë¶„ì„
# 3. ê°•í™” ì˜ì—­ ë° ì·¨ì•½ì  ì‹ë³„
# 4. êµ¬ì²´ì  ì‹¤í–‰ ê³„íš ì œì‹œ
```

---

## 10. í…ŒìŠ¤íŠ¸ ë° ë°°í¬

### 10.1 ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸

**Level 1: ëª¨ë“ˆë³„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**
```bash
# ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
python3 -m pytest tests/test_embeddings.py
python3 -m pytest tests/test_vector_db.py
python3 -m pytest tests/test_llm.py
```

**Level 2: API í†µí•© í…ŒìŠ¤íŠ¸**
```bash
# FastAPI í…ŒìŠ¤íŠ¸
python3 -m pytest tests/test_api.py

# ë˜ëŠ” ìˆ˜ë™ í…ŒìŠ¤íŠ¸
curl -X GET "http://localhost:8000/docs"
```

**Level 3: í”„ë¡ íŠ¸ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸**
```bash
# ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì‹¤ì œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
# 1. íŠ¹í—ˆ ê²€ìƒ‰
# 2. PDF ì—…ë¡œë“œ
# 3. AI ë¶„ì„
# 4. ê²°ê³¼ í‘œì‹œ
```

### 10.2 ë°°í¬ ì¤€ë¹„

**Step 1: í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì •**
```bash
# requirements.txt ì—…ë°ì´íŠ¸
pip freeze > requirements.txt

# Docker ì„¤ì • (ì„ íƒì‚¬í•­)
cat > Dockerfile << EOF
FROM python:3.9

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
EOF
```

**Step 2: í™˜ê²½ë³€ìˆ˜ ë³´ì•ˆ**
```bash
# í”„ë¡œë•ì…˜ìš© .env íŒŒì¼ ìƒì„±
cp .env .env.production

# API í‚¤ ë³´ì•ˆ ê°•í™”
chmod 600 .env.production
```

---

## ğŸ¯ **ì™„ì„±ëœ ì‹œìŠ¤í…œì˜ ì£¼ìš” ê¸°ëŠ¥**

### âœ… **êµ¬í˜„ ì™„ë£Œ ê¸°ëŠ¥**
1. **ğŸ” í†µí•© íŠ¹í—ˆ ê²€ìƒ‰**: í•œêµ­/ë¯¸êµ­ íŠ¹í—ˆì²­ + ë‚´ë¶€ DB
2. **ğŸ“„ PDF ìë™ ì²˜ë¦¬**: í•œê¸€ íŠ¹í—ˆ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
3. **ğŸ§  AI ë²¡í„° ê²€ìƒ‰**: ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ íŠ¹í—ˆ ë°œê²¬
4. **ğŸ¤– LLM ë¶„ì„**: GPTë¥¼ í™œìš©í•œ íŠ¹í—ˆ ê¸°ìˆ  ë¶„ì„
5. **ğŸ“Š ì „ëµ ìˆ˜ë¦½**: AI ê¸°ë°˜ íŠ¹í—ˆ ì „ëµ ì œì•ˆ
6. **ğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤**: ì‚¬ìš©ì ì¹œí™”ì  UI

### ğŸš€ **í™œìš© ë°©ë²•**
1. **ê¸°ì¡´ ì›¹ì‚¬ì´íŠ¸ì— AI ì„¹ì…˜ ì¶”ê°€**
2. **FastAPI ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰**
3. **íŠ¹í—ˆ PDF ì—…ë¡œë“œ ë° ìë™ ë¶„ì„**
4. **ì‹¤ì‹œê°„ íŠ¹í—ˆ ê²€ìƒ‰ ë° ìœ ì‚¬ë„ ë¶„ì„**
5. **AI ê¸°ë°˜ íŠ¹í—ˆ ì „ëµ ë¦¬í¬íŠ¸ ìƒì„±**

### ğŸ“ˆ **ê¸°ëŒ€ íš¨ê³¼**
- **50% ì‹œê°„ ë‹¨ì¶•**: ìˆ˜ë™ íŠ¹í—ˆ ê²€ìƒ‰ â†’ AI ìë™ ê²€ìƒ‰
- **95% ì •í™•ë„**: ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë°€ ë¶„ì„
- **ì „ëµì  ì˜ì‚¬ê²°ì •**: ë°ì´í„° ê¸°ë°˜ íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ì‹œë©´ Langchainì„ í™œìš©í•œ ì™„ì „í•œ AI íŠ¹í—ˆ ë¶„ì„ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰