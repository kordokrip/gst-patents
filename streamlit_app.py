"""
Streamlit ê¸°ë°˜ GST íŠ¹í—ˆ RAG ì±—ë´‡
----------------------------------
ì‹¤í–‰ ë°©ë²•:
    streamlit run streamlit_app.py

ì´ ì•±ì€ rag_outputs/ í´ë”ì˜ ì²­í¬ë¥¼ Pineconeì— ì—…ì„œíŠ¸í•˜ê³ ,
Pinecone + OpenAI LLMì„ ì´ìš©í•´ íŠ¹í—ˆ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import os
from html import escape
from pathlib import Path
from typing import Dict, List, Tuple
import time
import re

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from pinecone import Pinecone
import requests

from scripts.pinecone_ingest import (
    PINECONE_API_KEY,
    PINECONE_INDEX_NAME,
    PINECONE_NAMESPACE,
    EMBEDDING_MODEL,
    sync_rag_outputs,
)

load_dotenv()

CHAT_MODEL = os.getenv("OPENAI_CHAT_MODEL", "gpt-4o-mini")
PATENT_DOC_BASE_URL = os.getenv("PATENT_DOC_BASE_URL", "http://localhost:8080/data/patents")
WEB_SEARCH_ENABLED = os.getenv("WEB_SEARCH_ENABLED", "true").lower() == "true"

@st.cache_resource(show_spinner=False)
def init_clients():
    if not PINECONE_API_KEY:
        raise RuntimeError("Pinecone API Keyê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (.env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”).")
    pinecone_client = Pinecone(api_key=PINECONE_API_KEY)
    pinecone_index = pinecone_client.Index(PINECONE_INDEX_NAME)
    openai_client = OpenAI()
    return pinecone_index, openai_client


def embed_text(client: OpenAI, text: str) -> List[float]:
    response = client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=[text],
    )
    return response.data[0].embedding


def build_prompt(question: str, contexts: List[Dict], web_results: List[Dict]) -> str:
    context_blocks = []
    for ctx in contexts:
        content = ctx.get("content") or ctx.get("text") or ""
        title = ctx.get("title") or ctx.get("doc_id") or "ë¯¸ìƒ íŠ¹í—ˆ"
        page = ctx.get("page")
        tag = ctx.get("tag", "íŠ¹í—ˆ")
        header = f"[{tag}] ë¬¸ì„œ: {title}"
        if page is not None:
            header += f", í˜ì´ì§€ {page}"
        block = f"{header}\nì ìˆ˜: {ctx.get('score', 0):.3f}\në‚´ìš©:\n{content}"
        context_blocks.append(block.strip())

    combined_context = "\n\n".join(context_blocks)

    web_block = ""
    if web_results:
        entries = []
        for item in web_results:
            title = item.get("title") or "ì›¹ ê²€ìƒ‰ ê²°ê³¼"
            snippet = item.get("snippet") or ""
            link = item.get("link") or ""
            tag = item.get("tag", "ì›¹")
            entry = f"[{tag}] ì œëª©: {title}\nìš”ì•½: {snippet}\në§í¬: {link}"
            entries.append(entry.strip())
        web_block = "\n\n".join(entries)

    system_prompt = (
        "ë‹¹ì‹ ì€ GST íŠ¹í—ˆ ë°ì´í„°ì— ê¸°ë°˜í•œ ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ ë¬¸ë§¥ë§Œì„ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í™•ì‹ ì´ ì—†ì„ ê²½ìš° ì‚¬ì‹¤ëŒ€ë¡œ ë¶€ì¡±í•œ ì ì„ ë§ì”€í•˜ì„¸ìš”. "
        "í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
    )

    prompt = (
        f"{system_prompt}\n\n"
        f"[íŠ¹í—ˆ ë¬¸ë§¥]\n{combined_context if combined_context else 'ê´€ë ¨ íŠ¹í—ˆ ë¬¸ë§¥ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}\n\n"
    )

    if web_block:
        prompt += f"[ì›¹ ê²€ìƒ‰ ê²°ê³¼]\n{web_block}\n\n"

    prompt += (
        f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{question}\n\n"
        "ì‘ë‹µ ì‹œì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:\n"
        "- í•µì‹¬ ìš”ì•½\n"
        "- ìƒì„¸ ì„¤ëª…\n"
        "- ì‚¬ìš©í•œ ëª¨ë“  ê·¼ê±°ì— ëŒ€í•´ í•´ë‹¹ íƒœê·¸ë¥¼ ëŒ€ê´„í˜¸ë¡œ ì¸ìš© (ì˜ˆ: [íŠ¹í—ˆ1], [ì›¹2])\n"
        "- ë‹µë³€ ë§ˆì§€ë§‰ì— 'ì¶œì²˜:' ì„¹ì…˜ì„ ë§Œë“¤ê³  ì‚¬ìš©í•œ íƒœê·¸ë¥¼ ì œëª©ê³¼ í•¨ê»˜ bullet ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬\n"
        "- ì¶”ë¡  ê·¼ê±°ê°€ ë¶€ì¡±í•œ ê²½ìš°, ì¶”ê°€ ì •ë³´ í•„ìš”ì„±ì„ ëª…ì‹œ"
    )
    return prompt


def web_search(query: str, max_results: int = 4) -> List[Dict]:
    """
    ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ - DuckDuckGo ê²€ìƒ‰ (duckduckgo_search ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
    
    ì£¼ì˜: ì›¹ ê²€ìƒ‰ì€ íŠ¹í—ˆ ê²€ìƒ‰ì„ ë³´ì™„í•˜ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì‹¤ì œ íŠ¹í—ˆ ì •ë³´ëŠ” Pinecone ë²¡í„° DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if not WEB_SEARCH_ENABLED:
        return []
    
    try:
        # duckduckgo_search ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (requirements.txtì— ì¶”ê°€ í•„ìš”)
        from duckduckgo_search import DDGS
        
        with DDGS() as ddgs:
            results = []
            search_query = f"{query} íŠ¹í—ˆ OR patent"  # íŠ¹í—ˆ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
            
            for idx, result in enumerate(ddgs.text(search_query, max_results=max_results)):
                if idx >= max_results:
                    break
                    
                results.append({
                    "title": result.get("title", ""),
                    "snippet": result.get("body", "")[:300],  # 300ìë¡œ ì œí•œ
                    "link": result.get("href", ""),
                })
            
            # ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
            if results:
                print(f"[ì›¹ ê²€ìƒ‰] '{query}' - {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
            else:
                print(f"[ì›¹ ê²€ìƒ‰] '{query}' - ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                
            return results
            
    except ImportError:
        print("[ì›¹ ê²€ìƒ‰] duckduckgo_search ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("[ì›¹ ê²€ìƒ‰] pip install duckduckgo-search ì‹¤í–‰ í•„ìš”")
        return []
    except Exception as e:
        print(f"[ì›¹ ê²€ìƒ‰] ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}")
        return []


def run_query(
    question: str,
    top_k: int = 5,
    include_web: bool = True,
    web_results_limit: int = 4,
) -> Dict:
    index, client = init_clients()

    query_vector = embed_text(client, question)
    query_response = index.query(
        namespace=PINECONE_NAMESPACE,
        vector=query_vector,
        top_k=top_k,
        include_metadata=True,
        include_values=False,
    )

    matches = []
    for idx, match in enumerate(query_response.matches or [], start=1):
        metadata = match.metadata or {}
        metadata = metadata.copy()
        metadata.setdefault("score", match.score)
        metadata["tag"] = f"íŠ¹í—ˆ{idx}"
        matches.append(metadata)

    raw_web_results = web_search(question, web_results_limit) if include_web else []
    web_results = []
    for idx, item in enumerate(raw_web_results, start=1):
        enriched = item.copy()
        enriched["tag"] = f"ì›¹{idx}"
        web_results.append(enriched)

    prompt = build_prompt(question, matches, web_results)
    
    # OpenAI Chat Completion API í˜¸ì¶œ (ì˜¬ë°”ë¥¸ ë°©ì‹)
    chat_response = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ GST íŠ¹í—ˆ ë°ì´í„°ì— ê¸°ë°˜í•œ ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                    "ì£¼ì–´ì§„ ë¬¸ë§¥ë§Œì„ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í™•ì‹ ì´ ì—†ì„ ê²½ìš° ì‚¬ì‹¤ëŒ€ë¡œ ë¶€ì¡±í•œ ì ì„ ë§ì”€í•˜ì„¸ìš”. "
                    "í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": prompt,
            },
        ],
        temperature=0.3,  # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ temperature
        max_tokens=1500,
    )

    answer_text = chat_response.choices[0].message.content.strip()
    
    # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
    usage = chat_response.usage
    print(f"[OpenAI] ëª¨ë¸: {CHAT_MODEL}, í† í°: {usage.total_tokens} "
          f"(ì…ë ¥: {usage.prompt_tokens}, ì¶œë ¥: {usage.completion_tokens})")
    
    return {
        "answer": answer_text,
        "matches": matches,
        "web_results": web_results,
        "model_used": CHAT_MODEL,
        "tokens_used": usage.total_tokens,
    }


def sidebar_controls() -> Tuple[int, bool, int]:
    st.sidebar.header("âš™ï¸ Control Panel")
    
    # ì›¹ ê²€ìƒ‰ ì„¤ì •
    st.sidebar.subheader("ğŸŒ ì›¹ ê²€ìƒ‰ ì„¤ì •")
    include_web = st.sidebar.checkbox(
        "ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨", 
        value=WEB_SEARCH_ENABLED,
        help="ì²´í¬í•˜ë©´ íŠ¹í—ˆ DB ê²€ìƒ‰ ì™¸ì— ì›¹ ê²€ìƒ‰ ê²°ê³¼ë„ í¬í•¨ë©ë‹ˆë‹¤. (duckduckgo-search ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)"
    )
    web_results_limit = st.sidebar.slider("ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 1, 10, 3)
    
    if not WEB_SEARCH_ENABLED:
        st.sidebar.warning("âš ï¸ ì›¹ ê²€ìƒ‰ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (.envì˜ WEB_SEARCH_ENABLED=true ì„¤ì •)")
    
    st.sidebar.markdown("---")
    
    # Pinecone ê²€ìƒ‰ ì„¤ì •
    st.sidebar.subheader("ğŸ“š íŠ¹í—ˆ DB ê²€ìƒ‰")
    top_k = st.sidebar.slider(
        "Pinecone ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 
        1, 10, 5,
        help="ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ Nê°œì˜ íŠ¹í—ˆ ì²­í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
    )
    
    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ¤– AI ëª¨ë¸ ì •ë³´")
    st.sidebar.info(f"**ì‚¬ìš© ëª¨ë¸:** {CHAT_MODEL}\n**ì„ë² ë”©:** {EMBEDDING_MODEL}")

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ”§ ë°ì´í„° ë™ê¸°í™”")
    if st.sidebar.button("Pinecone ì—…ì„œíŠ¸ ì‹¤í–‰", use_container_width=True):
        with st.spinner("rag_outputs ë°ì´í„°ë¥¼ Pineconeì— ì—…ì„œíŠ¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            upserts, chunks, docs = sync_rag_outputs()
        st.sidebar.success(f"ì—…ì„œíŠ¸ ì™„ë£Œ: {upserts} ë²¡í„° (ì²­í¬ {chunks}ê°œ, ë¬¸ì„œ {docs}ê±´)")
    
    st.sidebar.markdown("---")
    st.sidebar.info(
        "ğŸ’¡ **ì‚¬ìš© íŒ**\n\n"
        "â€¢ íŠ¹í—ˆ ë²ˆí˜¸, ê¸°ìˆ ëª…, ë°œëª…ìëª… ë“±ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”\n"
        "â€¢ ì›¹ ê²€ìƒ‰ì€ ì°¸ê³ ìš©ì´ë©°, ì£¼ ë°ì´í„°ëŠ” íŠ¹í—ˆ DBì…ë‹ˆë‹¤\n"
        "â€¢ `.env` íŒŒì¼ì— OpenAI/Pinecone í‚¤ ì„¤ì • í•„ìš”\n"
        "â€¢ rag_outputs í´ë” ë‚´ìš© ë³€ê²½ ì‹œ ì—…ì„œíŠ¸ ì¬ì‹¤í–‰"
    )
    return top_k, include_web, web_results_limit


def sanitize_text(content: str) -> str:
    lines = content.split("\n")
    html_lines: List[str] = []
    in_list = False
    for raw_line in lines:
        line = raw_line.strip()
        if not line:
            if in_list:
                html_lines.append("</ul>")
                in_list = False
            continue
        if line.startswith("- "):
            if not in_list:
                html_lines.append("<ul>")
                in_list = True
            html_lines.append(f"<li>{escape(line[2:])}</li>")
        else:
            if in_list:
                html_lines.append("</ul>")
                in_list = False
            html_lines.append(f"<p>{escape(line)}</p>")
    if in_list:
        html_lines.append("</ul>")
    return "\n".join(html_lines) or "<p></p>"


def build_reference_block(patent_sources: List[Dict], web_sources: List[Dict]) -> str:
    sections = []
    if patent_sources:
        items = []
        for meta in patent_sources:
            title = escape(meta.get("title") or meta.get("doc_id") or "ë¯¸ìƒ ì œëª©")
            page = escape(str(meta.get("page", "ì •ë³´ ì—†ìŒ")))
            score = meta.get("score", 0.0)
            tag = escape(meta.get("tag", "íŠ¹í—ˆ"))
            url = meta.get("url")
            title_part = (
                f"<a href='{escape(url, quote=True)}' target='_blank' rel='noopener'><strong>{title}</strong></a>"
                if url
                else f"<strong>{title}</strong>"
            )
            items.append(f"<li>[{tag}] {title_part} Â· í˜ì´ì§€ {page} Â· ì ìˆ˜ {score:.3f}</li>")
        sections.append(
            "<div class='reference-group'><div class='reference-title'>ğŸ“˜ íŠ¹í—ˆ ê·¼ê±°</div>"
            f"<ul>{''.join(items)}</ul></div>"
        )
    if web_sources:
        items = []
        for item in web_sources:
            title = escape(item.get("title") or "ì›¹ ì¶œì²˜")
            snippet = escape(item.get("snippet") or "")
            link = escape(item.get("link") or "#")
            tag = escape(item.get("tag", "ì›¹"))
            items.append(
                f"<li>[{tag}] <a href='{link}' target='_blank' rel='noopener'>{title}</a>"
                f"{f' Â· {snippet}' if snippet else ''}</li>"
            )
        sections.append(
            "<div class='reference-group'><div class='reference-title'>ğŸŒ ì›¹ ê²€ìƒ‰</div>"
            f"<ul>{''.join(items)}</ul></div>"
        )
    if not sections:
        return ""
    return "<div class='reference-wrapper'>" + "".join(sections) + "</div>"


def build_patent_url(meta: Dict) -> str | None:
    doc_id = meta.get("doc_id")
    if doc_id:
        filename = f"{doc_id}.json"
        return f"{PATENT_DOC_BASE_URL}/{filename}"
    source_path = meta.get("source_path") or meta.get("source")
    if isinstance(source_path, str) and source_path.strip():
        name = Path(source_path).name
        if name:
            return f"{PATENT_DOC_BASE_URL}/{name}"
    return None


def source_cleanup(patent_sources: List[Dict]) -> List[Dict]:
    cleaned = []
    for meta in patent_sources or []:
        url = build_patent_url(meta)
        cleaned.append(
            {
                "title": meta.get("title") or meta.get("doc_id"),
                "doc_id": meta.get("doc_id"),
                "page": meta.get("page"),
                "score": meta.get("score"),
                "tag": meta.get("tag"),
                "content": meta.get("content") or meta.get("text"),
                "url": url,
            }
        )
    return cleaned


def ensure_sources_section(answer: str, patent_sources: List[Dict], web_sources: List[Dict]) -> str:
    answer = answer.strip()
    if not patent_sources and not web_sources:
        return answer

    if "ì¶œì²˜" in answer:
        return answer

    lines = [answer, "", "ì¶œì²˜:"]
    for meta in patent_sources or []:
        title = meta.get("title") or meta.get("doc_id") or "ë¯¸ìƒ ì œëª©"
        page = meta.get("page", "ì •ë³´ ì—†ìŒ")
        tag = meta.get("tag", "íŠ¹í—ˆ")
        url = meta.get("url") or build_patent_url(meta)
        if url:
            lines.append(f"- [{tag}] [{title}]({url}) (í˜ì´ì§€ {page})")
        else:
            lines.append(f"- [{tag}] {title} (í˜ì´ì§€ {page})")
    for item in web_sources or []:
        title = item.get("title") or "ì›¹ ì¶œì²˜"
        link = item.get("link") or ""
        tag = item.get("tag", "ì›¹")
        suffix = f" Â· {link}" if link else ""
        lines.append(f"- [{tag}] {title}{suffix}")
    return "\n".join(lines)


def build_message_html(role_class: str, label: str, content_html: str, reference_html: str = "") -> str:
    return (
        f"<div class='chat-message {role_class}'>"
        f"<div class='chat-label'>{label}</div>"
        f"<div class='chat-content'>{content_html}</div>"
        f"{reference_html}"
        "</div>"
    )


def typewriter_render(container, raw_text: str, references_html: str):
    placeholder = container.empty()
    tokens = re.split(r"(\s+)", raw_text)
    buffer = ""
    for token in tokens:
        buffer += token
        content_html = sanitize_text(buffer)
        html = build_message_html("assistant", "GST íŠ¹í—ˆ AI", content_html)
        placeholder.markdown(html, unsafe_allow_html=True)
        time.sleep(0.04)
    final_html = build_message_html("assistant", "GST íŠ¹í—ˆ AI", sanitize_text(raw_text), references_html)
    placeholder.markdown(final_html, unsafe_allow_html=True)


CUSTOM_CSS = """
<style>
/* Layout */
[data-testid="stAppViewContainer"] {
    background: radial-gradient(circle at top, #111827 0%, #0f172a 45%, #050910 100%);
    color: #e5e7eb;
    min-height: 100vh;
}
[data-testid="stMain"] {
    padding: 0;
}
[data-testid="stHeader"] {
    background: transparent;
}
.chat-wrapper {
    max-width: 980px;
    margin: 0 auto;
    padding: 2.5rem 1.5rem 8rem;
}
.chat-message {
    border-radius: 16px;
    padding: 1.4rem 1.6rem;
    margin-bottom: 1rem;
    line-height: 1.65;
    border: 1px solid rgba(148, 163, 184, 0.2);
    box-shadow: 0 10px 35px rgba(15, 23, 42, 0.25);
    backdrop-filter: blur(6px);
}
.chat-message.user {
    background: linear-gradient(135deg, rgba(59, 130, 246, 0.2), rgba(37, 99, 235, 0.15));
    border-color: rgba(96, 165, 250, 0.35);
}
.chat-message.assistant {
    background: linear-gradient(135deg, rgba(16, 185, 129, 0.28), rgba(20, 184, 166, 0.22));
    border-color: rgba(94, 234, 212, 0.35);
}
.chat-label {
    font-size: 0.85rem;
    font-weight: 700;
    letter-spacing: 0.05em;
    text-transform: uppercase;
    margin-bottom: 0.6rem;
}
.chat-message.user .chat-label {
    color: #60a5fa;
    text-align: right;
}
.chat-message.assistant .chat-label {
    color: #5eead4;
}
.chat-content p {
    margin: 0 0 0.8rem;
}
.chat-content ul {
    padding-left: 1.2rem;
    margin: 0.4rem 0 1rem;
}
.chat-content li {
    margin-bottom: 0.35rem;
}
.reference-wrapper {
    margin-top: 1.3rem;
    border-top: 1px solid rgba(148, 163, 184, 0.25);
    padding-top: 1rem;
}
.reference-title {
    font-size: 0.85rem;
    font-weight: 600;
    letter-spacing: 0.03em;
    color: rgba(244, 244, 245, 0.75);
    margin-bottom: 0.35rem;
}
.reference-wrapper ul {
    margin: 0;
    padding-left: 1.1rem;
    font-size: 0.92rem;
}
.reference-wrapper li {
    margin-bottom: 0.4rem;
}
.reference-wrapper a {
    color: #38bdf8;
    text-decoration: none;
}
.reference-wrapper a:hover {
    text-decoration: underline;
}

/* Sidebar */
[data-testid="stSidebar"] {
    background: rgba(15, 23, 42, 0.95);
    backdrop-filter: blur(8px);
    color: #e2e8f0;
}
[data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {
    color: #f8fafc;
}
[data-testid="stSidebar"] .stSlider label, [data-testid="stSidebar"] .stCheckbox label {
    font-weight: 600;
}

/* Chat input */
div[data-testid="stChatInput"] {
    background: rgba(15, 23, 42, 0.85);
    border-top: 1px solid rgba(148, 163, 184, 0.25);
}
div[data-testid="stChatInput"] textarea {
    background: rgba(15, 23, 42, 0.9);
    color: #e5e7eb;
}
</style>
"""


def main():
    st.set_page_config(page_title="GST íŠ¹í—ˆ AI ì§ˆì˜", page_icon="ğŸ¤–", layout="wide")
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

    st.markdown(
        """
        <div style="text-align:center; padding-top: 2rem;">
            <h1 style="font-size:2.2rem; color:#f8fafc; font-weight:800; letter-spacing:0.03em;">
                GST íŠ¹í—ˆ AI Copilot
            </h1>
            <p style="color:rgba(226,232,240,0.75); font-size:1.05rem; margin-top:0.5rem;">
                GST ì§€ëŠ¥í˜• íŠ¹í—ˆ ë¶„ì„ ë„ìš°ë¯¸ ğŸ¤–ğŸ’¡
            </p>
        </div>
        """,
        unsafe_allow_html=True,
    )

    top_k, include_web, web_results_limit = sidebar_controls()

    if "conversation" not in st.session_state:
        st.session_state.conversation = []

    chat_container = st.container()
    chat_container.markdown("<div class='chat-wrapper'>", unsafe_allow_html=True)

    for message in st.session_state.conversation:
        role_class = "user" if message["role"] == "user" else "assistant"
        label = "ì‚¬ìš©ì" if message["role"] == "user" else "GST íŠ¹í—ˆ AI"
        message_html = sanitize_text(message["content"])
        reference_html = ""
        if message["role"] == "assistant":
            reference_html = build_reference_block(
                message.get("sources") or [],
                message.get("web_sources") or [],
            )
        msg_container = chat_container.container()
        msg_container.markdown(
            build_message_html(role_class, label, message_html, reference_html),
            unsafe_allow_html=True,
        )

    pending_container = chat_container.container()
    closing_container = chat_container.container()
    closing_container.markdown("</div>", unsafe_allow_html=True)

    prompt = st.chat_input("íŠ¹í—ˆ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    if prompt:
        st.session_state.conversation.append({"role": "user", "content": prompt})
        with st.spinner("GST íŠ¹í—ˆ RAG ì±—ë´‡ ê´€ë ¨ ì§ˆë¬¸ì˜ ì •ë³´ì™€ íŠ¹í—ˆë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                result = run_query(
                    prompt,
                    top_k=top_k,
                    include_web=include_web,
                    web_results_limit=web_results_limit,
                )
                sources = result["matches"]
                web_sources = result["web_results"]
                answer = ensure_sources_section(result["answer"], sources, web_sources)
                clean_sources = source_cleanup(sources)
                references_html = build_reference_block(clean_sources, web_sources)
                typewriter_render(pending_container, answer, references_html)
                st.session_state.conversation.append(
                    {
                        "role": "assistant",
                        "content": answer,
                        "sources": clean_sources,
                        "web_sources": web_sources,
                    }
                )
            except Exception as exc:
                st.error(f"ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
                st.session_state.conversation.append(
                    {
                        "role": "assistant",
                        "content": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                        "sources": [],
                        "web_sources": [],
                    }
                )
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()


if __name__ == "__main__":
    main()
