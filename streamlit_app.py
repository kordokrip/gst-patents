"""
Streamlit ê¸°ë°˜ GST íŠ¹í—ˆ RAG ì±—ë´‡
----------------------------------
ì‹¤í–‰ ë°©ë²•:
    streamlit run streamlit_app.py

ì´ ì•±ì€ rag_outputs/ í´ë”ì˜ ì²­í¬ë¥¼ Pineconeì— ì—…ì„œíŠ¸í•˜ê³ ,
Pinecone + OpenAI LLMì„ ì´ìš©í•´ íŠ¹í—ˆ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import os
from html import escape
from pathlib import Path
from typing import Dict, List, Tuple
import time
import re

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from pinecone import Pinecone
import requests

from scripts.pinecone_ingest import (
    PINECONE_API_KEY,
    PINECONE_INDEX_NAME,
    PINECONE_NAMESPACE,
    EMBEDDING_MODEL,
    sync_rag_outputs,
)

load_dotenv()

CHAT_MODEL = os.getenv("OPENAI_CHAT_MODEL", "gpt-4o-mini")
PATENT_DOC_BASE_URL = os.getenv("PATENT_DOC_BASE_URL", "http://localhost:8080/data/patents")
WEB_SEARCH_ENABLED = os.getenv("WEB_SEARCH_ENABLED", "true").lower() == "true"

@st.cache_resource(show_spinner=False)
def init_clients():
    if not PINECONE_API_KEY:
        raise RuntimeError("Pinecone API Keyê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (.env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”).")
    pinecone_client = Pinecone(api_key=PINECONE_API_KEY)
    pinecone_index = pinecone_client.Index(PINECONE_INDEX_NAME)
    openai_client = OpenAI()
    return pinecone_index, openai_client


def embed_text(client: OpenAI, text: str) -> List[float]:
    response = client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=[text],
    )
    return response.data[0].embedding


def build_prompt(question: str, contexts: List[Dict], web_results: List[Dict]) -> str:
    context_blocks = []
    for ctx in contexts:
        content = ctx.get("content") or ctx.get("text") or ""
        title = ctx.get("title") or ctx.get("doc_id") or "ë¯¸ìƒ íŠ¹í—ˆ"
        page = ctx.get("page")
        tag = ctx.get("tag", "íŠ¹í—ˆ")
        header = f"[{tag}] ë¬¸ì„œ: {title}"
        if page is not None:
            header += f", í˜ì´ì§€ {page}"
        block = f"{header}\nì ìˆ˜: {ctx.get('score', 0):.3f}\në‚´ìš©:\n{content}"
        context_blocks.append(block.strip())

    combined_context = "\n\n".join(context_blocks)

    web_block = ""
    if web_results:
        entries = []
        for item in web_results:
            title = item.get("title") or "ì›¹ ê²€ìƒ‰ ê²°ê³¼"
            snippet = item.get("snippet") or ""
            link = item.get("link") or ""
            tag = item.get("tag", "ì›¹")
            entry = f"[{tag}] ì œëª©: {title}\nìš”ì•½: {snippet}\në§í¬: {link}"
            entries.append(entry.strip())
        web_block = "\n\n".join(entries)

    system_prompt = (
        "ë‹¹ì‹ ì€ GST íŠ¹í—ˆ ë°ì´í„°ì— ê¸°ë°˜í•œ ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ ë¬¸ë§¥ë§Œì„ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í™•ì‹ ì´ ì—†ì„ ê²½ìš° ì‚¬ì‹¤ëŒ€ë¡œ ë¶€ì¡±í•œ ì ì„ ë§ì”€í•˜ì„¸ìš”. "
        "í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
    )

    prompt = (
        f"{system_prompt}\n\n"
        f"[íŠ¹í—ˆ ë¬¸ë§¥]\n{combined_context if combined_context else 'ê´€ë ¨ íŠ¹í—ˆ ë¬¸ë§¥ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}\n\n"
    )

    if web_block:
        prompt += f"[ì›¹ ê²€ìƒ‰ ê²°ê³¼]\n{web_block}\n\n"

    prompt += (
        f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{question}\n\n"
        "ì‘ë‹µ ì‹œì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:\n"
        "- í•µì‹¬ ìš”ì•½\n"
        "- ìƒì„¸ ì„¤ëª…\n"
        "- ì‚¬ìš©í•œ ëª¨ë“  ê·¼ê±°ì— ëŒ€í•´ í•´ë‹¹ íƒœê·¸ë¥¼ ëŒ€ê´„í˜¸ë¡œ ì¸ìš© (ì˜ˆ: [íŠ¹í—ˆ1], [ì›¹2])\n"
        "- ë‹µë³€ ë§ˆì§€ë§‰ì— 'ì¶œì²˜:' ì„¹ì…˜ì„ ë§Œë“¤ê³  ì‚¬ìš©í•œ íƒœê·¸ë¥¼ ì œëª©ê³¼ í•¨ê»˜ bullet ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬\n"
        "- ì¶”ë¡  ê·¼ê±°ê°€ ë¶€ì¡±í•œ ê²½ìš°, ì¶”ê°€ ì •ë³´ í•„ìš”ì„±ì„ ëª…ì‹œ"
    )
    return prompt


def web_search(query: str, max_results: int = 4) -> List[Dict]:
    """
    íŠ¹í—ˆ ì „ë¬¸ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ - í•œêµ­/ì¼ë³¸/ë¯¸êµ­/ê¸°íƒ€ íŠ¹í—ˆì²­ ìµœì í™”
    
    ê²€ìƒ‰ ì†ŒìŠ¤:
    - í•œêµ­íŠ¹í—ˆì²­ (KIPRIS): patents.go.kr
    - ì¼ë³¸íŠ¹í—ˆì²­ (J-PlatPat): j-platpat.inpit.go.jp
    - ë¯¸êµ­íŠ¹í—ˆì²­ (USPTO): patents.google.com, uspto.gov
    - ìœ ëŸ½íŠ¹í—ˆì²­ (EPO): espacenet.com
    - ì¼ë°˜ ì›¹ ê²€ìƒ‰ (DuckDuckGo)
    
    ì£¼ì˜: ì›¹ ê²€ìƒ‰ì€ íŠ¹í—ˆ ê²€ìƒ‰ì„ ë³´ì™„í•˜ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì‹¤ì œ íŠ¹í—ˆ ì •ë³´ëŠ” Pinecone ë²¡í„° DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if not WEB_SEARCH_ENABLED:
        return []
    
    all_results = []
    
    try:
        from duckduckgo_search import DDGS
        
        # íŠ¹í—ˆ ë²ˆí˜¸ íŒ¨í„´ ê°ì§€
        patent_number_patterns = {
            'kr': re.compile(r'(KR|10-?\d{7})', re.IGNORECASE),
            'jp': re.compile(r'(JP|ç‰¹è¨±|ç‰¹é–‹|ç‰¹å…¬)\s*[\d-]+', re.IGNORECASE),
            'us': re.compile(r'(US|USD?)\s*[\d,]+', re.IGNORECASE),
        }
        
        detected_regions = []
        for region, pattern in patent_number_patterns.items():
            if pattern.search(query):
                detected_regions.append(region)
        
        # ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½
        search_strategies = []
        
        # 1. í•œêµ­ íŠ¹í—ˆ ê²€ìƒ‰ ì „ëµ
        if not detected_regions or 'kr' in detected_regions or any(
            keyword in query.lower() for keyword in ['ìŠ¤í¬ëŸ¬ë²„', 'ì¹ ëŸ¬', 'í”Œë¼ì¦ˆë§ˆ', 'ë°˜ë„ì²´']
        ):
            search_strategies.append({
                'query': f'{query} site:patents.go.kr OR site:kipris.or.kr',
                'region': 'ğŸ‡°ğŸ‡· í•œêµ­íŠ¹í—ˆì²­',
                'priority': 10
            })
            search_strategies.append({
                'query': f'{query} íŠ¹í—ˆ í•œêµ­',
                'region': 'ğŸ‡°ğŸ‡· í•œêµ­',
                'priority': 8
            })
        
        # 2. ì¼ë³¸ íŠ¹í—ˆ ê²€ìƒ‰ ì „ëµ
        if 'jp' in detected_regions or any(
            keyword in query for keyword in ['æ—¥æœ¬', 'ã‚¹ã‚¯ãƒ©ãƒãƒ¼', 'ãƒãƒ©ãƒ¼']
        ):
            search_strategies.append({
                'query': f'{query} site:j-platpat.inpit.go.jp',
                'region': 'ğŸ‡¯ğŸ‡µ ì¼ë³¸íŠ¹í—ˆì²­',
                'priority': 10
            })
            search_strategies.append({
                'query': f'{query} ç‰¹è¨± æ—¥æœ¬',
                'region': 'ğŸ‡¯ğŸ‡µ ì¼ë³¸',
                'priority': 8
            })
        
        # 3. ë¯¸êµ­ íŠ¹í—ˆ ê²€ìƒ‰ ì „ëµ
        if 'us' in detected_regions or any(
            keyword in query.lower() for keyword in ['scrubber', 'chiller', 'plasma']
        ):
            search_strategies.append({
                'query': f'{query} site:patents.google.com OR site:uspto.gov',
                'region': 'ğŸ‡ºğŸ‡¸ ë¯¸êµ­íŠ¹í—ˆì²­',
                'priority': 10
            })
            search_strategies.append({
                'query': f'{query} patent USA',
                'region': 'ğŸ‡ºğŸ‡¸ ë¯¸êµ­',
                'priority': 8
            })
        
        # 4. ìœ ëŸ½ ë° êµ­ì œ íŠ¹í—ˆ ê²€ìƒ‰
        search_strategies.append({
            'query': f'{query} site:espacenet.com OR site:epo.org',
            'region': 'ğŸ‡ªğŸ‡º ìœ ëŸ½íŠ¹í—ˆì²­',
            'priority': 6
        })
        
        # 5. ì¼ë°˜ íŠ¹í—ˆ ê²€ìƒ‰ (í´ë°±)
        search_strategies.append({
            'query': f'{query} patent OR ç‰¹è¨± OR íŠ¹í—ˆ',
            'region': 'ğŸŒ ê¸€ë¡œë²Œ',
            'priority': 5
        })
        
        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        search_strategies.sort(key=lambda x: x['priority'], reverse=True)
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results_per_strategy = max(2, max_results // min(len(search_strategies), 3))
        
        with DDGS() as ddgs:
            for strategy in search_strategies[:3]:  # ìƒìœ„ 3ê°œ ì „ëµë§Œ ì‹¤í–‰
                try:
                    print(f"[ì›¹ ê²€ìƒ‰] {strategy['region']} - ì¿¼ë¦¬: {strategy['query'][:50]}...")
                    
                    for idx, result in enumerate(
                        ddgs.text(strategy['query'], max_results=results_per_strategy)
                    ):
                        if idx >= results_per_strategy:
                            break
                        
                        # ì¤‘ë³µ ì œê±°
                        url = result.get("href", "")
                        if any(r['link'] == url for r in all_results):
                            continue
                        
                        all_results.append({
                            "title": result.get("title", ""),
                            "snippet": result.get("body", "")[:300],
                            "link": url,
                            "region": strategy['region'],
                            "priority": strategy['priority']
                        })
                        
                        if len(all_results) >= max_results:
                            break
                    
                    if len(all_results) >= max_results:
                        break
                        
                except Exception as strategy_error:
                    print(f"[ì›¹ ê²€ìƒ‰] {strategy['region']} ì „ëµ ì‹¤íŒ¨: {strategy_error}")
                    continue
        
        # ìš°ì„ ìˆœìœ„ ë° ê´€ë ¨ì„± ê¸°ë°˜ ì •ë ¬
        all_results.sort(key=lambda x: (
            x.get('priority', 0),
            # íŠ¹í—ˆì²­ ì‚¬ì´íŠ¸ ìš°ì„ 
            1 if any(domain in x['link'] for domain in [
                'patents.go.kr', 'kipris.or.kr', 
                'j-platpat.inpit.go.jp',
                'patents.google.com', 'uspto.gov',
                'espacenet.com', 'epo.org'
            ]) else 0
        ), reverse=True)
        
        # ê²°ê³¼ ì œí•œ
        all_results = all_results[:max_results]
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
        if all_results:
            print(f"[ì›¹ ê²€ìƒ‰] '{query}' - {len(all_results)}ê°œ ê²°ê³¼ ë°œê²¬")
            for idx, result in enumerate(all_results, 1):
                print(f"  {idx}. [{result.get('region', 'ğŸŒ')}] {result['title'][:50]}...")
        else:
            print(f"[ì›¹ ê²€ìƒ‰] '{query}' - ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        
        return all_results
        
    except ImportError:
        print("[ì›¹ ê²€ìƒ‰] duckduckgo_search ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("[ì›¹ ê²€ìƒ‰] pip install duckduckgo-search ì‹¤í–‰ í•„ìš”")
        return []
    except Exception as e:
        print(f"[ì›¹ ê²€ìƒ‰] ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}")
        return []


def run_query(
    question: str,
    top_k: int = 5,
    include_web: bool = True,
    web_results_limit: int = 4,
) -> Dict:
    index, client = init_clients()

    query_vector = embed_text(client, question)
    query_response = index.query(
        namespace=PINECONE_NAMESPACE,
        vector=query_vector,
        top_k=top_k,
        include_metadata=True,
        include_values=False,
    )

    matches = []
    for idx, match in enumerate(query_response.matches or [], start=1):
        metadata = match.metadata or {}
        metadata = metadata.copy()
        metadata.setdefault("score", match.score)
        metadata["tag"] = f"íŠ¹í—ˆ{idx}"
        matches.append(metadata)

    raw_web_results = web_search(question, web_results_limit) if include_web else []
    web_results = []
    for idx, item in enumerate(raw_web_results, start=1):
        enriched = item.copy()
        enriched["tag"] = f"ì›¹{idx}"
        web_results.append(enriched)

    prompt = build_prompt(question, matches, web_results)
    
    # OpenAI Chat Completion API í˜¸ì¶œ (ì˜¬ë°”ë¥¸ ë°©ì‹)
    chat_response = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ GST íŠ¹í—ˆ ë°ì´í„°ì— ê¸°ë°˜í•œ ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                    "ì£¼ì–´ì§„ ë¬¸ë§¥ë§Œì„ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í™•ì‹ ì´ ì—†ì„ ê²½ìš° ì‚¬ì‹¤ëŒ€ë¡œ ë¶€ì¡±í•œ ì ì„ ë§ì”€í•˜ì„¸ìš”. "
                    "í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": prompt,
            },
        ],
        temperature=0.3,  # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ temperature
        max_tokens=1500,
    )

    answer_text = chat_response.choices[0].message.content.strip()
    
    # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
    usage = chat_response.usage
    print(f"[OpenAI] ëª¨ë¸: {CHAT_MODEL}, í† í°: {usage.total_tokens} "
          f"(ì…ë ¥: {usage.prompt_tokens}, ì¶œë ¥: {usage.completion_tokens})")
    
    return {
        "answer": answer_text,
        "matches": matches,
        "web_results": web_results,
        "model_used": CHAT_MODEL,
        "tokens_used": usage.total_tokens,
    }


def sidebar_controls() -> Tuple[int, bool, int]:
    st.sidebar.header("âš™ï¸ Control Panel")
    
    # ì›¹ ê²€ìƒ‰ ì„¤ì •
    st.sidebar.subheader("ğŸŒ ì›¹ ê²€ìƒ‰ ì„¤ì •")
    include_web = st.sidebar.checkbox(
        "ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨", 
        value=WEB_SEARCH_ENABLED,
        help="ì²´í¬í•˜ë©´ íŠ¹í—ˆ DB ê²€ìƒ‰ ì™¸ì— ì›¹ ê²€ìƒ‰ ê²°ê³¼ë„ í¬í•¨ë©ë‹ˆë‹¤. (duckduckgo-search ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)"
    )
    web_results_limit = st.sidebar.slider("ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 1, 10, 3)
    
    if not WEB_SEARCH_ENABLED:
        st.sidebar.warning("âš ï¸ ì›¹ ê²€ìƒ‰ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (.envì˜ WEB_SEARCH_ENABLED=true ì„¤ì •)")
    
    st.sidebar.markdown("---")
    
    # Pinecone ê²€ìƒ‰ ì„¤ì •
    st.sidebar.subheader("ğŸ“š íŠ¹í—ˆ DB ê²€ìƒ‰")
    top_k = st.sidebar.slider(
        "Pinecone ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 
        1, 10, 5,
        help="ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ Nê°œì˜ íŠ¹í—ˆ ì²­í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
    )
    
    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ¤– AI ëª¨ë¸ ì •ë³´")
    st.sidebar.info(f"**ì‚¬ìš© ëª¨ë¸:** {CHAT_MODEL}\n**ì„ë² ë”©:** {EMBEDDING_MODEL}")

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ”§ ë°ì´í„° ë™ê¸°í™”")
    if st.sidebar.button("Pinecone ì—…ì„œíŠ¸ ì‹¤í–‰", use_container_width=True):
        with st.spinner("rag_outputs ë°ì´í„°ë¥¼ Pineconeì— ì—…ì„œíŠ¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            upserts, chunks, docs = sync_rag_outputs()
        st.sidebar.success(f"ì—…ì„œíŠ¸ ì™„ë£Œ: {upserts} ë²¡í„° (ì²­í¬ {chunks}ê°œ, ë¬¸ì„œ {docs}ê±´)")
    
    st.sidebar.markdown("---")
    st.sidebar.info(
        "ğŸ’¡ **ì‚¬ìš© íŒ**\n\n"
        "â€¢ íŠ¹í—ˆ ë²ˆí˜¸, ê¸°ìˆ ëª…, ë°œëª…ìëª… ë“±ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”\n"
        "â€¢ ì›¹ ê²€ìƒ‰ì€ í•œ/ì¼/ë¯¸/ìœ ëŸ½ íŠ¹í—ˆì²­ ìµœì í™”\n"
        "  - ğŸ‡°ğŸ‡· í•œêµ­: patents.go.kr, kipris.or.kr\n"
        "  - ğŸ‡¯ğŸ‡µ ì¼ë³¸: j-platpat.inpit.go.jp\n"
        "  - ğŸ‡ºğŸ‡¸ ë¯¸êµ­: patents.google.com, uspto.gov\n"
        "  - ğŸ‡ªğŸ‡º ìœ ëŸ½: espacenet.com\n"
        "â€¢ íŠ¹í—ˆë²ˆí˜¸ ê°ì§€ ì‹œ í•´ë‹¹ êµ­ê°€ ìš°ì„  ê²€ìƒ‰\n"
        "â€¢ `.env` íŒŒì¼ì— OpenAI/Pinecone í‚¤ ì„¤ì • í•„ìš”\n"
        "â€¢ rag_outputs í´ë” ë‚´ìš© ë³€ê²½ ì‹œ ì—…ì„œíŠ¸ ì¬ì‹¤í–‰"
    )
    return top_k, include_web, web_results_limit


def sanitize_text(content: str) -> str:
    lines = content.split("\n")
    html_lines: List[str] = []
    in_list = False
    for raw_line in lines:
        line = raw_line.strip()
        if not line:
            if in_list:
                html_lines.append("</ul>")
                in_list = False
            continue
        if line.startswith("- "):
            if not in_list:
                html_lines.append("<ul>")
                in_list = True
            html_lines.append(f"<li>{escape(line[2:])}</li>")
        else:
            if in_list:
                html_lines.append("</ul>")
                in_list = False
            html_lines.append(f"<p>{escape(line)}</p>")
    if in_list:
        html_lines.append("</ul>")
    return "\n".join(html_lines) or "<p></p>"


def build_reference_block(patent_sources: List[Dict], web_sources: List[Dict]) -> str:
    sections = []
    if patent_sources:
        items = []
        for meta in patent_sources:
            title = escape(meta.get("title") or meta.get("doc_id") or "ë¯¸ìƒ ì œëª©")
            page = escape(str(meta.get("page", "ì •ë³´ ì—†ìŒ")))
            score = meta.get("score", 0.0)
            tag = escape(meta.get("tag", "íŠ¹í—ˆ"))
            url = meta.get("url")
            title_part = (
                f"<a href='{escape(url, quote=True)}' target='_blank' rel='noopener'><strong>{title}</strong></a>"
                if url
                else f"<strong>{title}</strong>"
            )
            items.append(f"<li>[{tag}] {title_part} Â· í˜ì´ì§€ {page} Â· ì ìˆ˜ {score:.3f}</li>")
        sections.append(
            "<div class='reference-group'><div class='reference-title'>ğŸ“˜ íŠ¹í—ˆ ê·¼ê±°</div>"
            f"<ul>{''.join(items)}</ul></div>"
        )
    if web_sources:
        items = []
        for item in web_sources:
            title = escape(item.get("title") or "ì›¹ ì¶œì²˜")
            snippet = escape(item.get("snippet") or "")
            link = escape(item.get("link") or "#")
            tag = escape(item.get("tag", "ì›¹"))
            region = escape(item.get("region", "ğŸŒ"))
            items.append(
                f"<li>[{tag}] {region} <a href='{link}' target='_blank' rel='noopener'>{title}</a>"
                f"{f' Â· {snippet}' if snippet else ''}</li>"
            )
        sections.append(
            "<div class='reference-group'><div class='reference-title'>ğŸŒ ì›¹ ê²€ìƒ‰ (íŠ¹í—ˆì²­ ìµœì í™”)</div>"
            f"<ul>{''.join(items)}</ul></div>"
        )
    if not sections:
        return ""
    return "<div class='reference-wrapper'>" + "".join(sections) + "</div>"


def build_patent_url(meta: Dict) -> str | None:
    doc_id = meta.get("doc_id")
    if doc_id:
        filename = f"{doc_id}.json"
        return f"{PATENT_DOC_BASE_URL}/{filename}"
    source_path = meta.get("source_path") or meta.get("source")
    if isinstance(source_path, str) and source_path.strip():
        name = Path(source_path).name
        if name:
            return f"{PATENT_DOC_BASE_URL}/{name}"
    return None


def source_cleanup(patent_sources: List[Dict]) -> List[Dict]:
    cleaned = []
    for meta in patent_sources or []:
        url = build_patent_url(meta)
        cleaned.append(
            {
                "title": meta.get("title") or meta.get("doc_id"),
                "doc_id": meta.get("doc_id"),
                "page": meta.get("page"),
                "score": meta.get("score"),
                "tag": meta.get("tag"),
                "content": meta.get("content") or meta.get("text"),
                "url": url,
            }
        )
    return cleaned


def ensure_sources_section(answer: str, patent_sources: List[Dict], web_sources: List[Dict]) -> str:
    answer = answer.strip()
    if not patent_sources and not web_sources:
        return answer

    if "ì¶œì²˜" in answer:
        return answer

    lines = [answer, "", "ì¶œì²˜:"]
    for meta in patent_sources or []:
        title = meta.get("title") or meta.get("doc_id") or "ë¯¸ìƒ ì œëª©"
        page = meta.get("page", "ì •ë³´ ì—†ìŒ")
        tag = meta.get("tag", "íŠ¹í—ˆ")
        url = meta.get("url") or build_patent_url(meta)
        if url:
            lines.append(f"- [{tag}] [{title}]({url}) (í˜ì´ì§€ {page})")
        else:
            lines.append(f"- [{tag}] {title} (í˜ì´ì§€ {page})")
    for item in web_sources or []:
        title = item.get("title") or "ì›¹ ì¶œì²˜"
        link = item.get("link") or ""
        tag = item.get("tag", "ì›¹")
        suffix = f" Â· {link}" if link else ""
        lines.append(f"- [{tag}] {title}{suffix}")
    return "\n".join(lines)


def build_message_html(role_class: str, label: str, content_html: str, reference_html: str = "") -> str:
    return (
        f"<div class='chat-message {role_class}'>"
        f"<div class='chat-label'>{label}</div>"
        f"<div class='chat-content'>{content_html}</div>"
        f"{reference_html}"
        "</div>"
    )


def typewriter_render(container, raw_text: str, references_html: str):
    placeholder = container.empty()
    tokens = re.split(r"(\s+)", raw_text)
    buffer = ""
    for token in tokens:
        buffer += token
        content_html = sanitize_text(buffer)
        html = build_message_html("assistant", "GST íŠ¹í—ˆ AI", content_html)
        placeholder.markdown(html, unsafe_allow_html=True)
        time.sleep(0.04)
    final_html = build_message_html("assistant", "GST íŠ¹í—ˆ AI", sanitize_text(raw_text), references_html)
    placeholder.markdown(final_html, unsafe_allow_html=True)


CUSTOM_CSS = """
<style>
/* Layout */
[data-testid="stAppViewContainer"] {
    background: radial-gradient(circle at top, #111827 0%, #0f172a 45%, #050910 100%);
    color: #e5e7eb;
    min-height: 100vh;
}
[data-testid="stMain"] {
    padding: 0;
}
[data-testid="stHeader"] {
    background: transparent;
}
.chat-wrapper {
    max-width: 980px;
    margin: 0 auto;
    padding: 2.5rem 1.5rem 8rem;
}
.chat-message {
    border-radius: 16px;
    padding: 1.4rem 1.6rem;
    margin-bottom: 1rem;
    line-height: 1.65;
    border: 1px solid rgba(148, 163, 184, 0.2);
    box-shadow: 0 10px 35px rgba(15, 23, 42, 0.25);
    backdrop-filter: blur(6px);
}
.chat-message.user {
    background: linear-gradient(135deg, rgba(59, 130, 246, 0.2), rgba(37, 99, 235, 0.15));
    border-color: rgba(96, 165, 250, 0.35);
}
.chat-message.assistant {
    background: linear-gradient(135deg, rgba(16, 185, 129, 0.28), rgba(20, 184, 166, 0.22));
    border-color: rgba(94, 234, 212, 0.35);
}
.chat-label {
    font-size: 0.85rem;
    font-weight: 700;
    letter-spacing: 0.05em;
    text-transform: uppercase;
    margin-bottom: 0.6rem;
}
.chat-message.user .chat-label {
    color: #60a5fa;
    text-align: right;
}
.chat-message.assistant .chat-label {
    color: #5eead4;
}
.chat-content p {
    margin: 0 0 0.8rem;
}
.chat-content ul {
    padding-left: 1.2rem;
    margin: 0.4rem 0 1rem;
}
.chat-content li {
    margin-bottom: 0.35rem;
}
.reference-wrapper {
    margin-top: 1.3rem;
    border-top: 1px solid rgba(148, 163, 184, 0.25);
    padding-top: 1rem;
}
.reference-title {
    font-size: 0.85rem;
    font-weight: 600;
    letter-spacing: 0.03em;
    color: rgba(244, 244, 245, 0.75);
    margin-bottom: 0.35rem;
}
.reference-wrapper ul {
    margin: 0;
    padding-left: 1.1rem;
    font-size: 0.92rem;
}
.reference-wrapper li {
    margin-bottom: 0.4rem;
}
.reference-wrapper a {
    color: #38bdf8;
    text-decoration: none;
}
.reference-wrapper a:hover {
    text-decoration: underline;
}

/* Sidebar */
[data-testid="stSidebar"] {
    background: rgba(15, 23, 42, 0.95);
    backdrop-filter: blur(8px);
    color: #e2e8f0;
}
[data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {
    color: #f8fafc;
}
[data-testid="stSidebar"] .stSlider label, [data-testid="stSidebar"] .stCheckbox label {
    font-weight: 600;
}

/* Chat input */
div[data-testid="stChatInput"] {
    background: rgba(15, 23, 42, 0.85);
    border-top: 1px solid rgba(148, 163, 184, 0.25);
}
div[data-testid="stChatInput"] textarea {
    background: rgba(15, 23, 42, 0.9);
    color: #e5e7eb;
}
</style>
"""


def main():
    st.set_page_config(page_title="GST íŠ¹í—ˆ AI ì§ˆì˜", page_icon="ğŸ¤–", layout="wide")
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

    st.markdown(
        """
        <div style="text-align:center; padding-top: 2rem;">
            <h1 style="font-size:2.2rem; color:#f8fafc; font-weight:800; letter-spacing:0.03em;">
                GST íŠ¹í—ˆ AI Copilot
            </h1>
            <p style="color:rgba(226,232,240,0.75); font-size:1.05rem; margin-top:0.5rem;">
                GST ì§€ëŠ¥í˜• íŠ¹í—ˆ ë¶„ì„ ë„ìš°ë¯¸ ğŸ¤–ğŸ’¡
            </p>
        </div>
        """,
        unsafe_allow_html=True,
    )

    top_k, include_web, web_results_limit = sidebar_controls()

    if "conversation" not in st.session_state:
        st.session_state.conversation = []

    chat_container = st.container()
    chat_container.markdown("<div class='chat-wrapper'>", unsafe_allow_html=True)

    for message in st.session_state.conversation:
        role_class = "user" if message["role"] == "user" else "assistant"
        label = "ì‚¬ìš©ì" if message["role"] == "user" else "GST íŠ¹í—ˆ AI"
        message_html = sanitize_text(message["content"])
        reference_html = ""
        if message["role"] == "assistant":
            reference_html = build_reference_block(
                message.get("sources") or [],
                message.get("web_sources") or [],
            )
        msg_container = chat_container.container()
        msg_container.markdown(
            build_message_html(role_class, label, message_html, reference_html),
            unsafe_allow_html=True,
        )

    pending_container = chat_container.container()
    closing_container = chat_container.container()
    closing_container.markdown("</div>", unsafe_allow_html=True)

    prompt = st.chat_input("íŠ¹í—ˆ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    if prompt:
        st.session_state.conversation.append({"role": "user", "content": prompt})
        with st.spinner("GST íŠ¹í—ˆ RAG ì±—ë´‡ ê´€ë ¨ ì§ˆë¬¸ì˜ ì •ë³´ì™€ íŠ¹í—ˆë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                result = run_query(
                    prompt,
                    top_k=top_k,
                    include_web=include_web,
                    web_results_limit=web_results_limit,
                )
                sources = result["matches"]
                web_sources = result["web_results"]
                answer = ensure_sources_section(result["answer"], sources, web_sources)
                clean_sources = source_cleanup(sources)
                references_html = build_reference_block(clean_sources, web_sources)
                typewriter_render(pending_container, answer, references_html)
                st.session_state.conversation.append(
                    {
                        "role": "assistant",
                        "content": answer,
                        "sources": clean_sources,
                        "web_sources": web_sources,
                    }
                )
            except Exception as exc:
                st.error(f"ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
                st.session_state.conversation.append(
                    {
                        "role": "assistant",
                        "content": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                        "sources": [],
                        "web_sources": [],
                    }
                )
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()


if __name__ == "__main__":
    main()
